# PUNTO 1 y 2 â€”  ExtracciÃ³n y TransformaciÃ³n de Datos (Web Scraping + ETL)

# 1. IntroducciÃ³n General

La **Universidad Santo TomÃ¡s** se encuentra en un proceso de modernizaciÃ³n tecnolÃ³gica, buscando optimizar sus flujos de trabajo mediante soluciones basadas en **inteligencia artificial**, **visiÃ³n por computador** y **automatizaciÃ³n**.

Dentro de este proceso, se solicitÃ³ el diseÃ±o e implementaciÃ³n de un sistema capaz de:

* Construir una **base de datos extensa** con imÃ¡genes de elementos de laboratorio de electrÃ³nica.
* Automatizar el proceso de adquisiciÃ³n mediante tÃ©cnicas de **web scraping**. 
* Utilizar **concurrencia** (hilos), **semÃ¡foros**, **exclusiÃ³n mutua** y **colas seguras** para incrementar el rendimiento.
* Generar **metadatos consistentes** para su posterior uso en modelos con MediaPipe.

---

Este informe documenta en profundidad la **arquitectura del *software***, los fundamentos teÃ³ricos empleados y las **decisiones tÃ©cnicas** que guiaron el desarrollo.

El Ã©nfasis estÃ¡ en la implementaciÃ³n de **hilos**, **semÃ¡foros**, **mutex** y **sincronizaciÃ³n concurrente**.

---
# 2. JustificaciÃ³n del uso de Web Scraping con Concurrencia

## 2.1. La necesidad de scraping masivo

Cada clase de objeto debÃ­a contar con **mÃ­nimo 200 imÃ¡genes**, y el proyecto incluÃ­a inicialmente **10 clases** (multÃ­metro, osciloscopio, protoboard, cautÃ­n, fuente de poder, generador de funciones, motor paso a paso, transformador, resistencia, capacitor).

Esto implicaba recolectar **2000 imÃ¡genes vÃ¡lidas**, no duplicadas, descargadas, verificadas y almacenadas en el menor tiempo posible.

El *scraping* secuencial se considerÃ³ inviable por las siguientes razones:
* **AltÃ­simos tiempos de espera** (latencia de red, en este caso mas de 10 horas para dos clases).
* Dependencia de redes externas lentas.
* Necesidad de **validar imÃ¡genes manualmente** (proceso lento).
* **Riesgo alto de bloqueo** por parte del motor de bÃºsqueda (por la alta frecuencia de peticiones desde un Ãºnico hilo).

> 

La **soluciÃ³n Ã³ptima** para cumplir con los requisitos de volumen y tiempo debÃ­a ser inherentemente **concurrente**.

---

## 3. Fundamentos TeÃ³ricos de Concurrencia Aplicados

Esta secciÃ³n profundiza en la teorÃ­a que fundamenta la implementaciÃ³n utilizada.
# 3.1. Hilos (Threads)

Los **hilos** (`Threads`) permiten ejecutar mÃºltiples tareas de forma **concurrente** dentro de un mismo proceso, compartiendo memoria, variables y archivos.

### AplicaciÃ³n en este Proyecto
En este proyecto de *web scraping* masivo:
* Cada hilo es un **consumidor** de la cola de URLs.
* Se encarga de descargar una imagen, verificarla, procesarla, guardarla y registrar sus metadatos.

### Ventajas de usar hilos en Web Scraping
El uso de hilos fue crÃ­tico debido a que el *scraping* es una tarea limitada por operaciones de Entrada/Salida (**I/O-bound**):

| Ventaja | DescripciÃ³n |
| :--- | :--- |
| **Alta latencia de red** | Mientras un hilo espera a que se complete una descarga de red, otros pueden avanzar. |
| **CPU poco utilizada** | El proceso estÃ¡ limitado por la I/O, no por procesamiento de CPU. |
| **Bajo consumo de memoria** | Comparado con la creaciÃ³n de mÃºltiples procesos independientes (*multiprocessing*). |
| **Simplicidad de estado** | Es mÃ¡s sencillo compartir y sincronizar el estado global (contador por clase, CSV de metadatos, cola de URLs). |

### JustificaciÃ³n 
El *scraping* es una tarea tÃ­picamente I/O-bound, lo cual se beneficia del modelo de hilos incluso con la presencia del **GIL (Global Interpreter Lock)** de Python, ya que:

* El **GIL se libera** durante operaciones de red que esperan datos.
* La descarga de imÃ¡genes no compite por tiempo de CPU.
* Los hilos se ejecutan de manera eficiente sin necesidad de recurrir a la complejidad del *multiprocessing*.

---

# 3.2. ExclusiÃ³n Mutua â€” Mutex / Lock

**Problema:** Los hilos comparten recursos sensibles, como:

* El archivo **`metadata.csv`** (para registrar los datos).
* Los **contadores de imÃ¡genes** por categorÃ­a (para nombrar archivos).
* Los Ã­ndices para nombres de archivos.
* La carpeta donde se guardan las imÃ¡genes.

Sin protecciÃ³n, aparece el riesgo de **condiciones de carrera** (*race conditions*).

### ğŸš¨ Ejemplo de CondiciÃ³n de Carrera real:

Dos hilos revisan simultÃ¡neamente cuÃ¡ntas imÃ¡genes lleva la categorÃ­a "multimeter":

```bash
Hilo 1 â†’ ve que hay 50
Hilo 2 â†’ ve que hay 50
Ambos deciden guardar la imagen como multimeter_00051.jpg
```
- Resultado: Se sobrescribe un archivo o se corrompe el dataset.

- SoluciÃ³n:

  - Se implementÃ³:
    ```bash
    counter_lock = threading.Lock()
    ```
  - Este mutex garantiza:

    - Acceso exclusivo a las secciones crÃ­ticas.

    - Escritura ordenada en metadata.csv.

    - Que solo un hilo manipule los contadores.

    - GeneraciÃ³n correcta de nombres de archivos.

    - Evitar duplicados generados por carreras.

  # 3.3. SemaforizaciÃ³n â€” Control de Conexiones SimultÃ¡neas

Los **SemÃ¡foros** se emplean para **limitar el nÃºmero de conexiones abiertas simultÃ¡neamente** a la red, actuando como un contador de permisos.

### ImplementaciÃ³n:
Se utilizÃ³ un semÃ¡foro para restringir cuÃ¡ntos hilos pueden estar descargando activamente en un momento dado:

```bash
download_semaphore = threading.Semaphore(MAX_SIMULTANEOUS_DOWNLOADS)
```

- Â¿Por quÃ© era necesario un SemÃ¡foro?

  - El semÃ¡foro es crucial para la robustez del scraper debido a los siguientes riesgos:

      - Bloqueo de IPs: Los servicios de imÃ¡genes (como Bing) bloquean o imponen CAPTCHAs a IPs que realizan descargas excesivas en paralelo en un corto perÃ­odo de tiempo.

      - PatrÃ³n sospechoso: Sin lÃ­mite, 8 hilos podrÃ­an generar 8 conexiones simultÃ¡neas cada segundo, lo que se identifica como un patrÃ³n de ataque o bot.

      - SaturaciÃ³n: El sistema podrÃ­a saturar la red local o el motor de bÃºsqueda, provocando timeouts continuos y un rendimiento inestable.

      - FunciÃ³n: El semÃ¡foro pone en espera a los hilos que exceden el lÃ­mite, asegurando que solo un nÃºmero controlado (MAX_SIMULTANEOUS_DOWNLOADS) acceda a los recursos de red a la vez.

  ### **CÃ³mo funciona**

    - Antes de descargar una imagen:
    ```bash
    download_semaphore.acquire()
    ```
    Cuando finaliza:
    ```bash
    download_semaphore.release()
    ```
  ### **Analizando el impacto**

- Al limitar a 5 conexiones simultÃ¡neas se logrÃ³:

  - Mantener trÃ¡fico estable.

  - Evitar bloqueos por parte del servidor.

  - Permitir a los demÃ¡s hilos continuar descargando en paralelo.

# 3.4. Cola de Tareas â€” Productor/Consumidor

La arquitectura se diseÃ±Ã³ como:

- Productor

  - Produce URLs obtenidas con Selenium.

  - Las inserta en la cola:
```bash
download_queue.put((url, label))
```
- Consumidores

  - Hilos que obtienen tareas:
```bash
item = download_queue.get()
```
  - Procesan la descarga, verificaciÃ³n, y guardado.

 ## 4. Arquitectura del Sistema Desarrollado

La arquitectura final del sistema de extracciÃ³n y descarga se estructurÃ³ en los siguientes **mÃ³dulos** principales:

---

### 1. MÃ³dulo Selenium

Este mÃ³dulo es el Productor de tareas, encargado de la extracciÃ³n de las URLs objetivo.

* **FunciÃ³n:** Extrae cientos de URLs tanto de miniaturas como de las imÃ¡genes de alta definiciÃ³n (reales).
* **Mecanismo:** Se desplazÃ³ dinÃ¡micamente por la plataforma **Bing Images**.
* **TÃ©cnica Clave:** Aprovecha el evento de **click en las miniaturas** para exponer y obtener las URLs de las imÃ¡genes en calidad HD.

---

### 2. MÃ³dulo de Cola de URLs

ActÃºa como el buffer central entre los mÃ³dulos de extracciÃ³n y los de descarga.

* **FunciÃ³n Principal:** Administra el **backlog de trabajo** (las URLs extraÃ­das).
* **Control de Flujo:** Controla el ritmo y el flujo de las tareas que serÃ¡n entregadas a los **hilos consumidores**.

---

### 3. MÃ³dulo Multithreading

Este mÃ³dulo implementa la concurrencia para la descarga eficiente de archivos.

* **FunciÃ³n:** Ejecuta **mÃºltiples descargas en paralelo** para maximizar el rendimiento.
* **Principio:** Cada hilo de trabajo opera de forma **independiente y segura** al procesar su tarea asignada.

---

### 4. Gestores de SincronizaciÃ³n

Componentes esenciales para garantizar la seguridad y el orden en el entorno concurrente.

* **`Lock`:** Se utiliza para **proteger datos compartidos** de condiciones de carrera (ej., al actualizar un contador global).
* **`SemÃ¡foro`:** Se emplea para **controlar las conexiones simultÃ¡neas** a la fuente externa, evitando la sobrecarga o el bloqueo por parte del servidor de destino.

---

### 5. MÃ³dulo de Metadatos

Asegura la trazabilidad y la integridad de los datos descargados.

* **Almacenamiento:** Guarda la informaciÃ³n esencial de cada imagen: **nombre, tamaÃ±o, URL y el hash SHA256**.
* **Beneficios:**
    * Asegura la **reproducibilidad** del proceso.
    * Permite la **detecciÃ³n futura de duplicados** de manera infalible.

---

### 6. Depuradores Posteriores

Scripts complementarios ejecutados tras la finalizaciÃ³n de las descargas.

* **FunciÃ³n 1:** **EliminaciÃ³n de imÃ¡genes corruptas** o incompletas.
* **FunciÃ³n 2:** Realiza la **deduplicaciÃ³n** final por hash (`SHA256`) utilizando scripts de apoyo.

## 5. Problemas Reales Durante el Desarrollo y Soluciones

Esta secciÃ³n detalla los principales obstÃ¡culos encontrados durante la implementaciÃ³n y las soluciones tÃ©cnicas aplicadas, lo que demuestra el cumplimiento de objetivos y el aprendizaje tÃ©cnico adquirido.

---

## 5.1. Descarga de imÃ¡genes irrelevantes

El principal desafÃ­o en la fase de extracciÃ³n fue la **baja precisiÃ³n** de los resultados de bÃºsqueda de la fuente (`Bing Images`).

* **Problema Real:** Al buscar un tÃ©rmino tÃ©cnico y especÃ­fico como **"multimeter"** (multÃ­metro), la herramienta de bÃºsqueda tendÃ­a a devolver imÃ¡genes contextualmente irrelevantes, tales como sillas, escritorios o fotografÃ­as de personas utilizando el multÃ­metro, en lugar del dispositivo en sÃ­.
* **Soluciones Aplicadas:**
    1.  **Ajuste del Keyword:** Se implementÃ³ una estrategia de **ajuste fino de los tÃ©rminos de bÃºsqueda** para intentar acotar los resultados.
    2.  **Curado en Limpieza Posterior:** Se asumiÃ³ una fase de **curado manual o semiautomÃ¡tico** como parte del proceso de limpieza posterior para descartar imÃ¡genes no deseadas.
    3.  **Balance de Dataset:** Posteriormente, para diversificar y mejorar la calidad del conjunto de datos, se aÃ±adiÃ³ el tÃ©rmino **"transistor"** a la lista de keywords, buscando **balancear** la tipologÃ­a de las imÃ¡genes.

---

### 5.2. Tiempo excesivo de ExtracciÃ³n (>10 horas)

La optimizaciÃ³n del tiempo de ejecuciÃ³n fue crÃ­tica, ya que el proceso inicial consumÃ­a una cantidad de tiempo inaceptable para la escala de datos requerida.

* **Problema Real:** La extracciÃ³n de aproximadamente **2000 imÃ¡genes limpias** requiriÃ³ un tiempo de ejecuciÃ³n excesivamente largo, lo que afectÃ³ la productividad y la iteraciÃ³n del desarrollo:
    * **5 horas** con Firefox (El proceso fallÃ³ por errores de perfil del navegador).
    * **MÃ¡s de 10 horas en total** para completar las extracciones de solo dos clases con la implementaciÃ³n inicial de **Selenium**.
* **Intentos de SoluciÃ³n Fallidos:**
    * Se intentÃ³ alternar el *driver* de Selenium entre **Chromium** y **Firefox** para buscar una ganancia de rendimiento, sin Ã©xito significativo.
    * Se evaluaron mÃ©todos externos como la librerÃ­a **`bing_image_downloader`**, pero se descartaron por falta de flexibilidad o control.
* **SoluciÃ³n Final Adoptada (CombinaciÃ³n de Enfoques):**
    1.  **Scraping Multithreading:** Se implementÃ³ y optimizÃ³ un sistema de **scraping concurrente** utilizando **`multithreading`** para manejar la mayorÃ­a de las descargas en paralelo.
    2.  **Herramienta Alternativa EspecÃ­fica:** Se utilizÃ³ una **herramienta alternativa especÃ­fica** para la extracciÃ³n del subconjunto de imÃ¡genes de **"transistores"**, aprovechando su eficiencia para esa tarea concreta.
    3.  **Limpieza Posterior AutomÃ¡tica:** La dependencia en una **limpieza posterior automÃ¡tica** se incrementÃ³ para manejar la escala de datos extraÃ­dos rÃ¡pidamente, compensando la velocidad de extracciÃ³n con un proceso de filtrado robusto.

### 5.3. EliminaciÃ³n masiva â€” PÃ©rdida del 40â€“60% de imÃ¡genes

DespuÃ©s del dedupe por hash:
  ```bash
  Eliminados: 1189
  ```
- Causas:

  - ImÃ¡genes duplicadas en miniaturas/HD.

  - Servidores devolvÃ­an la misma imagen con URLs diferentes.

  - Historias de cache del buscador.

- Resultado final:

  - Todas las carpetas quedaron con mÃ¡s de 100 imÃ¡genes vÃ¡lidas.
  - Aunque no se alcanzÃ³ exactamente 200 por clase, el dataset es consistente y limpio.

  ## 7. Conclusiones del Punto 1: Logros y Aprendizajes

La ejecuciÃ³n exitosa de este proyecto de construcciÃ³n de dataset y sistema de scraping condujo a los siguientes logros y aprendizajes clave:

---

### Logros del Proyecto

* **ConstrucciÃ³n de un Dataset Personalizado para el Laboratorio:** Se logrÃ³ crear un dataset de alta calidad, curado y especÃ­fico, con una cantidad de mÃ¡s de 100 imÃ¡genes por clase despuÃ©s de la fase de limpieza y depuraciÃ³n.
* **Desarrollo de un Sistema de Scraping Robusto y Realista:** Se diseÃ±Ã³ y codificÃ³ un sistema de extracciÃ³n que demostrÃ³ ser capaz de realizar trabajo intensivo de larga duraciÃ³n, resolviendo desafÃ­os reales de estabilidad y gestiÃ³n de errores.
* **ImplementaciÃ³n de TÃ©cnicas Avanzadas de Concurrencia:** Se aplicaron con Ã©xito principios de multithreading y sincronizaciÃ³n (Lock, Semaphore) en una aplicaciÃ³n real, con impactos tangibles en la reducciÃ³n del tiempo de procesamiento.

---

### Aprendizajes Clave

* **LÃ­mites y Fallos Comunes del Scraping:** Se obtuvo una experiencia prÃ¡ctica profunda en el manejo y mitigaciÃ³n de problemas intrÃ­nsecos al web scraping a gran escala, incluyendo:
    * **Bloqueos de IP:** Estrategias para evadir o manejar las restricciones del servidor fuente.
    * **ImÃ¡genes Ruidosas:** GestiÃ³n de imÃ¡genes con contenido contextual irrelevante.
    * **Contenidos No Relevantes:** Filtrado efectivo de resultados que no cumplen con los requisitos de la clase (ej., errores de keyword).
    * **Duplicados Masivos:** ImplementaciÃ³n de hashing (SHA256) para la detecciÃ³n y eliminaciÃ³n eficiente.

* **GeneraciÃ³n de una Arquitectura Escalable:** El diseÃ±o modular y desacoplado del sistema sentÃ³ las bases para la escalabilidad y la integraciÃ³n futura con mÃ³dulos de Machine Learning para los siguientes objetivos del proyecto:
    * ClasificaciÃ³n con MediaPipe.
    * Reconocimiento de elementos.
    * ImplementaciÃ³n del sistema final en Streamlit.

  ---

## ğŸ“ Estructura del proyecto: tree + explicaciÃ³n completa

A continuaciÃ³n se muestra la estructura final del proyecto de Web Scraping con Python, enriquecida con una explicaciÃ³n exhaustiva de cada componente:

**webscrapping/**
* **venv/**
    * ... (Entorno virtual con dependencias)
* **dataset/**
    * [Carpetas de Clases]
        * breadboard/
        * capacitor_electronic_component/
        * diode_electronic_component/
        * function_generator/
        * multimeter/
        * oscilloscope/
        * resistor_electronic_component/
        * soldering_iron/
        * stepper_motor/
        * transistor_electronic_component/
* **metadata/**
    * metadata.csv (Registro formal y trazabilidad del dataset)
* **Archivos Ejecutables y Scripts**
    * scraper\_dataset.py (Scraper PRINCIPAL: Multihilo, SemÃ¡foros, Mutex)
    * fast\_download\_transistor.py (Script alterno/de emergencia)
    * check\_corrupt.py (Script para detectar y registrar imÃ¡genes daÃ±adas)
    * dedupe\_by\_hash.py (Script para eliminaciÃ³n masiva de duplicados por hash SHA-256)
    * README.md (DocumentaciÃ³n principal del proyecto)
  * **Dockerfile**
  * **requirements.txt**

## ğŸ§© ExplicaciÃ³n de las Carpetas y Archivos Principales

A continuaciÃ³n se detalla la funciÃ³n de cada directorio y archivo clave dentro de la estructura del proyecto.

---

### 1. `venv/` â€” Entorno Virtual ğŸ§ª

Este directorio es esencial para la gestiÃ³n de dependencias del proyecto. 

* **FunciÃ³n Principal:** Contiene todas las **dependencias de Python** de forma aislada del sistema operativo principal.
* **PropÃ³sito:**
    * **Evita conflictos de versiones** con librerÃ­as o paquetes instalados globalmente en el sistema.
    * Aloja librerÃ­as especÃ­ficas utilizadas en el proyecto, como **`requests`**, **`Pillow`**, **`bing_image_downloader`**, **`beautifulsoup4`**, etc.
    * **Garantiza la portabilidad:** Asegura que cualquier desarrollador que ejecute el proyecto tenga **exactamente el mismo entorno** de trabajo.
* **Estatus:** Es una carpeta indispensable para el desarrollo profesional y reproducible de proyectos en Python.

---

### 2. `dataset/` â€” Carpetas con las ImÃ¡genes Finales ğŸ’¾

Este directorio almacena la salida principal del proceso de *scraping* y limpieza: el conjunto de datos final.

* **FunciÃ³n Principal:** Contiene todas las **clases (categorÃ­as)** que componen el *dataset*.
* **Estructura Interna:** Cada clase se representa mediante una subcarpeta dentro de `dataset/`.
* **Nomenclatura:** Las carpetas de clase tienen un **nombre normalizado** para facilitar el procesamiento posterior por modelos de Machine Learning.

- Ejemplos:

  - breadboard/

  - multimeter/

  - transistor_electronic_component/

  Cada carpeta dentro de `dataset/` contiene las siguientes caracterÃ­sticas despuÃ©s del proceso de curado:

* **ImÃ¡genes VÃ¡lidas:** Solo incluye imÃ¡genes que han pasado el proceso de deduplicaciÃ³n (sin duplicados).
* **ImÃ¡genes NO Corruptas:** Todos los archivos han sido verificados y garantizan su integridad estructural.
* **Cantidad Final:** **MÃ¡s de 100 imÃ¡genes por clase** despuÃ©s de la limpieza.

> **Nota:** Aunque el objetivo inicial era de 200 imÃ¡genes por clase, los desafÃ­os inherentes al *scraping* (problemas de precisiÃ³n en Bing, el exceso de imÃ¡genes basura y la enorme cantidad de duplicados) redujeron el total final. Esta limitaciÃ³n cuantitativa se justifica y explica detalladamente en el **README tÃ©cnico** del proyecto.

---

### 3. `metadata/metadata.csv` â€” Registro Formal del Dataset ğŸ“„

Este archivo es crucial para la **trazabilidad, auditorÃ­a y reproducibilidad** del conjunto de datos. En proyectos serios de *Machine Learning* y anÃ¡lisis de datos, el registro formal del origen y estado de cada muestra es un requisito clave.



**Campos TÃ­picos del `metadata.csv`:**

| Campo | DescripciÃ³n |
| :--- | :--- |
| `image_path` | La ruta relativa al archivo dentro de la carpeta `dataset/`. |
| `class` | La categorÃ­a o etiqueta a la que pertenece la imagen (ej. 'multimeter', 'transistor'). |
| `resolution` | La resoluciÃ³n de la imagen (ej. '640x480'). |
| `file_size` | El tamaÃ±o del archivo en bytes. |
| `hash_sha256` | El **hash criptogrÃ¡fico SHA256**, fundamental para la detecciÃ³n de duplicados y la verificaciÃ³n de integridad. |
| `is_corrupt` | Indicador booleano que registra si la imagen fue marcada como corrupta (deberÃ­a ser **False** para todas las entradas finales). |
| `duplicate_of` | Si es un duplicado, registra el `image_path` del archivo original que se conservÃ³. |

## 4. `scraper_dataset.py` â€” Scraper PRINCIPAL Multihilo (con SemÃ¡foros y Mutex)

Este script es el **archivo mÃ¡s importante y central** de todo el proyecto, conteniendo la lÃ³gica de concurrencia y la gestiÃ³n robusta de errores para la descarga de imÃ¡genes.

---

### Funcionalidades Clave y TÃ©cnicas de Concurrencia

El script implementa tÃ©cnicas avanzadas de programaciÃ³n concurrente para optimizar el rendimiento y garantizar la integridad de los datos:

* **Uso de Threads (Hilos):**
    * **PropÃ³sito:** Se utilizan para ejecutar la descarga de **mÃºltiples imÃ¡genes en paralelo**. 
    * **Impacto:** Sin la concurrencia, el proceso de *scraping* habrÃ­a tardado un estimado de **40 a 60 horas**.

* **Uso de SemÃ¡foros (`Semaphore`):**
    * **FunciÃ³n:** Se implementa un **semÃ¡foro** para **limitar el nÃºmero de descargas simultÃ¡neas** a un valor seguro (ejemplo: `semaphore = threading.Semaphore(8)`).
    * **Beneficios:**
        * Evita **bans temporales** por parte de la fuente (`Bing Images`).
        * Previene **errores por saturaciÃ³n** del servidor de destino.
        * Minimiza **timeouts masivos** y el riesgo de saturar la CPU o el ancho de banda local.

* **Uso de Mutex (`Lock`):**
    * **Necesidad:** El mutex (o `Lock`) es necesario porque, aunque las imÃ¡genes se descargan en paralelo, **varios hilos deben escribir simultÃ¡neamente** en recursos compartidos, como:
        * El archivo de registro de metadatos (`metadata.csv`).
        * **Contadores globales** de progreso o errores.
    * **Resultado:** El uso del mutex **evita *race conditions*** (condiciones de carrera) y previene la **corrupciÃ³n** del archivo CSV, garantizando la escritura atÃ³mica de los datos.

---

### GestiÃ³n de Errores y Almacenamiento

El script garantiza la fiabilidad del proceso de descarga mediante control de calidad y robustez:

* **Descarga con Control de Errores Robusto:**
    * **Manejo de Timeouts:** Implementa estrategias de reintento ante fallos de conexiÃ³n o tiempos de espera agotados.
    * **Retry AutomÃ¡tico:** Intenta automÃ¡ticamente la descarga un nÃºmero predefinido de veces antes de marcar una tarea como fallida.
    * **SanitizaciÃ³n del Nombre del Archivo:** Procesa y limpia el nombre del archivo para asegurar la compatibilidad con diferentes sistemas operativos.
    * **VerificaciÃ³n de Contenido:** Valida que el archivo descargado sea efectivamente una imagen (ej., contenido tipo `image/jpeg`, `image/png`), descartando posibles archivos HTML o corruptos.

* **Guardado y OrganizaciÃ³n:** Guarda cada imagen en su **carpeta de clase correspondiente** dentro del directorio `dataset/`, manteniendo la estructura organizada.

### 5. `fast_download_transistor.py` â€” Script Alterno de Emergencia ğŸš€

Este script fue desarrollado como una **soluciÃ³n de contingencia** para mitigar los problemas de eficiencia y precisiÃ³n del *scraper* principal en clases problemÃ¡ticas.

* **MotivaciÃ³n:** Se creÃ³ debido a:
    * El tiempo excesivo de ejecuciÃ³n del *scraper* principal (**mÃ¡s de 10 horas**).
    * El fallo en completar el objetivo de 200 imÃ¡genes en algunas clases.
    * La alta tasa de **imÃ¡genes irrelevantes** (sillas, autos, etc.) devueltas por Bing.
    * El componente **"transistor"** fue particularmente problemÃ¡tico en la extracciÃ³n.

* **ImplementaciÃ³n:** Utiliza la librerÃ­a **`bing_image_downloader`**, pero requiriÃ³ una **modificaciÃ³n interna del mÃ³dulo** debido a:
    * Un **bug** relacionado con la funciÃ³n `Path.isdir` en el entorno de desarrollo.
    * La necesidad de **adaptar el flujo de descarga** para integrarlo con la estructura de carpetas del proyecto.

* **Uso:** Solo se empleÃ³ una vez para **completar una clase puntual** (la de transistores) y balancear el *dataset*.

---

### 6. `check_corrupt.py` â€” Script para Detectar ImÃ¡genes DaÃ±adas ğŸ›¡ï¸

Este script de post-procesamiento garantiza la **integridad y usabilidad** de todos los archivos descargados.

* **Mecanismo de VerificaciÃ³n:** Revisa iterativamente cada archivo dentro del directorio `dataset/`.
    * **Proceso:** Intenta abrir la imagen utilizando la librerÃ­a **PIL (Pillow)**.
    * **AcciÃ³n:** Si la apertura falla, la imagen es marcada como **corrupta** y el estado se **registra en `metadata.csv`**. Opcionalmente, el script puede ser configurado para eliminar el archivo fÃ­sicamente.

* **Importancia CrÃ­tica:** Este script fue **crucial** porque:
    * Bing entregÃ³ una cantidad significativamente alta de **imÃ¡genes corruptas** o incompletas.
    * Se detectaron casos de archivos que eran realmente **cÃ³digo HTML disfrazado de JPG** (un error comÃºn de *scraping*).

---

### 7. `dedupe_by_hash.py` â€” EliminaciÃ³n Masiva de Duplicados âš™ï¸

Este script asegura la **unicidad** del *dataset*, un paso fundamental para evitar el sesgo en el entrenamiento de modelos de *Machine Learning*.

* **Proceso Central:**
    * **CÃ¡lculo de Hash:** Calcula el **hash SHA-256** de cada imagen. Esta es la tÃ©cnica mÃ¡s robusta y **garantiza detectar duplicados** incluso si los archivos tienen nombres o metadatos distintos. 
    * **EliminaciÃ³n:** **Elimina automÃ¡ticamente los duplicados reales**. En la ejecuciÃ³n del proyecto, el resultado fue: **Eliminados: 1189** archivos.

* **JustificaciÃ³n de Duplicados:** La alta tasa de duplicados es normal debido a:
    * La repeticiÃ³n masiva de contenido por parte de la fuente (`Bing`).
    * La similitud entre las clases del *dataset*.
    * La tendencia del buscador a devolver **clones reescalados** de la misma imagen.

* **Registro:** **Actualiza el `metadata.csv`**, marcando cuÃ¡l archivo fue duplicado de cuÃ¡l, manteniendo un registro de la limpieza.

![Image](https://github.com/user-attachments/assets/87457fb1-c937-48c2-b33d-3907dcc1ac2c)
>- Carpetas
---

![Image](https://github.com/user-attachments/assets/f716ea5b-7411-4878-80f3-75370a5ab821)
>- Dataset luego del primer web scrapping (sin limpieza)
---


![Image](https://github.com/user-attachments/assets/9ed39431-7098-4396-848e-860c054e8628)
>- VerificaciÃ³n imagenes corruptas
---

![Image](https://github.com/user-attachments/assets/f1d3aa2e-0535-4a78-ab7a-7c0679a83069)
>- Limpieza de imagenes 
---
![Image](https://github.com/user-attachments/assets/7a29297c-70a9-456e-8e5b-2bf1c23a2d70)
>- Limpieza semantica de imagenes ejemplo 1
---

![Image](https://github.com/user-attachments/assets/e6d7a427-5322-43e7-8d54-0ef314cc91fc)
>- Limpieza semantica de imagenes ejemplo 2
---

![Image](https://github.com/user-attachments/assets/3f3d7489-9a38-4b8d-ad4f-1af62686d606)
>- Limpieza semantica de imagenes ejemplo 3
---

![Image](https://github.com/user-attachments/assets/e5b0c03b-132c-475b-97d4-8f8d0a91936d)
>- Cantidad de imagenes despues de la limpieza
---

![Image](https://github.com/user-attachments/assets/80ca9f7a-c417-40f2-b8ef-f4cca9ddaeec)
>- Cantidad de imagenes despues de un nuevo web scrapping y limpieza
---


![Image](https://github.com/user-attachments/assets/3f6283f9-6d0e-4a83-a686-0a926118ed67)
>- Redimension de imÃ¡genes y conteo final
---

# Punto 3 - Sistema de DetecciÃ³n en Tiempo Real con Streamlit, YOLO, Seguimiento de Velocidad y Docker ğŸ³

En este punto  se integra un sistema completo para visiÃ³n artificial en tiempo real, combinando:

- DetecciÃ³n de personas
- CÃ¡lculo de velocidad por seguimiento con Centroid Tracking
- DetecciÃ³n de componentes electrÃ³nicos (osciloscopio, multÃ­metro, raspberryâ€¦) con YOLO personalizado
- Procesamiento paralelo (multithreading) con semaforizaciÃ³n natural usando colas
- Interfaz web en tiempo real desarrollada en Streamlit
- ContenedorizaciÃ³n con Docker
- Entrenamiento de un clasificador CNN
- GeneraciÃ³n automÃ¡tica de clases

------------

## ğŸ—ï¸ 1. Arquitectura General del Proyecto

El sistema se divide en mÃ³dulos independientes que cooperan:    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Streamlit (Frontend)     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
            ActualizaciÃ³n UI
                   â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚        Procesos              â”‚
    â”‚  (Threads independientes)    â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚              â”‚               â”‚
    â–¼              â–¼               â–¼
    Captura     Personas         Componentes
      |        (Tracking)           (YOLO)
      |             |                |
      â””â”€â”€â”€â”€â”€â”€â–º Cola Q â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Cada mÃ³dulo corre en un hilo separado, sincronizado mediante queues, que funcionan como buffers que evitan bloqueos y regulan el acceso concurrente (semaforizaciÃ³n implÃ­cita).

------------

## ğŸ¥ 2. MÃ³dulo de Captura de Video â€” VideoCaptureThread

ğŸ“Œ Encargado de:

- Abrir la cÃ¡mara
- Leer frames continuamente (sin bloquear la interfaz)
- Duplicar cada frame hacia dos pipelines independientes:
	- frame_q_person â†’ DetecciÃ³n y velocidad
	- frame_q_comp â†’ YOLO componentes

âœ”ï¸ Se usa time.sleep(0.01) para evitar overrun
âœ”ï¸ El hilo es daemon, cierra automÃ¡ticamente
âœ”ï¸ Los buffers Queue(maxsize=2) cumplen funciÃ³n de mutex + semÃ¡foro

- Si la cola estÃ¡ llena, descarta entrada â†’ evita backpressure

------------

# Punto 3 - Sistema de DetecciÃ³n en Tiempo Real con Streamlit, YOLO, Seguimiento de Velocidad y Docker ğŸ³

En este punto  se integra un sistema completo para visiÃ³n artificial en tiempo real, combinando tÃ©cnicas avanzadas de visiÃ³n artificial, arquitectura concurrente y despliegue en contenedores. A continuaciÃ³n se explica el funcionamiento interno hasta las decisiones de diseÃ±o tomadas durante el desarrollo.

------------

## ğŸ“Œ Contenido

1. Arquitectura completa del sistema
2. MÃ³dulo de captura
3. MÃ³dulo de seguimiento y velocidad
4. Hilo de detecciÃ³n por YOLO
5. Interfaz visual con Streamlit
6. Scripts auxiliares
7. DockerizaciÃ³n completa
8. Errores encontrados y decisiones de diseÃ±o
9. ExplicaciÃ³n profunda de hilos, semÃ¡foros y mutex
10. 

------------

## ğŸ—ï¸ 1. Arquitectura General del Sistema

El sistema fue diseÃ±ado bajo procesamiento paralelo, manteniendo una UI fluida incluso mientras:

- Se captura video en tiempo real
- Se procesan personas y su velocidad
- Se ejecutan modelos YOLO personalizados
- Se actualiza la interfaz en dos paneles simultÃ¡neamente

Esto se logra mediante tres hilos principales:

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚       Streamlit (UI)         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
            ActualizaciÃ³n de la UI
                    â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚      Procesos (threads) â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚      â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â” â”Œâ”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ CapturaVideo â”‚ â”‚ YOLOComponent â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                â”‚
        Frame duplicado      Frame duplicado
               â”‚                â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ Cola personas â”‚   â”‚ Cola comp   â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â–¼               â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚         PersonProcessor              â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Cada mÃ³dulo corre en un hilo separado, sincronizado mediante queues, que funcionan como buffers que evitan bloqueos y regulan el acceso concurrente (semaforizaciÃ³n implÃ­cita).

Los Queue(maxsize=2) actÃºan como:

âœ” mini-buffers
âœ” semÃ¡foros implÃ­citos
âœ” reguladores de concurrencia
âœ” anti-lag para evitar cuellos de botella

------------

## ğŸ¥ 2. MÃ³dulo de Captura de Video â€” VideoCaptureThread

ğŸ“Œ Encargado de:

- Abrir la cÃ¡mara
- Leer frames continuamente (sin bloquear la interfaz)
- Duplicar cada frame hacia dos pipelines independientes:
	- frame_q_person â†’ DetecciÃ³n y velocidad
	- frame_q_comp â†’ YOLO componentes

âœ”ï¸ Se usa time.sleep(0.01) para evitar overrun
âœ”ï¸ El hilo es daemon, cierra automÃ¡ticamente
âœ”ï¸ Los buffers Queue(maxsize=2) cumplen funciÃ³n de mutex + semÃ¡foro

- Si la cola estÃ¡ llena, descarta entrada â†’ evita backpressure

Este hilo es el corazÃ³n del sistema porque:

### âœ” Evita que Streamlit se bloquee

Un error comÃºn es capturar frames directamente dentro de Streamlit, lo cual congela la UI.
AquÃ­, capturamos en un hilo dedicado.

### âœ” DuplicaciÃ³n de frames

Cada frame leÃ­do se divide hacia dos pipelines independientes:

- personas â†’ anÃ¡lisis de velocidad
- componentes â†’ YOLO personalizado

Esto es mÃ¡s eficiente que abrir la cÃ¡mara dos veces.

### âœ” Â¿CÃ³mo funciona la semaforizaciÃ³n?

La cola funciona como un semÃ¡foro:

- Si la cola estÃ¡ llena â†’ descarta frames viejos
- Si estÃ¡ vacÃ­a â†’ el thread consumidor espera

Esto evita condiciones de carrera.

------------

## ğŸƒâ€â™‚ï¸ğŸ’¨ 3. Seguimiento y Velocidad â€” PersonProcessor

Este mÃ³dulo combina:

### 1ï¸âƒ£ DetecciÃ³n de personas

Preferencia:

1. MobileNetSSD (ligero, eficiente)
2. YOLOv11n (si no estÃ¡ MobileNet)

### 2ï¸âƒ£ CentroidTracker personalizado

El sistema identifica cada persona con un ID constante.

Incluye:

- Registro
- DesapariciÃ³n gradual
- ReasignaciÃ³n inteligente por distancias

### 3ï¸âƒ£ CÃ¡lculo real de velocidad

Sistema basado en:

    velocidad = distancia_en_metros / tiempo

Donde:

    metros = pixeles * pixels_to_m

Este valor se calibra desde la UI.

### 4ï¸âƒ£ Suavizado con historial

Historial de centroides â†’ evita ruido â†’ velocidad estable.

------------

## ğŸ› ï¸ 4. DetecciÃ³n de Componentes â€” ComponentsProcessor

Este mÃ³dulo carga el modelo YOLO personalizado:

    /home/arley/segmentacion/model/best.pt

Clases detectadas:

- MultÃ­metro
- Osciloscopio
- Raspberry Pi

âœ” Verbose desactivado â†’ mÃ¡s rendimiento
âœ” Colores distintos por clase
âœ” TambiÃ©n usa colas para semaforizaciÃ³n
âœ” Procesamiento completamente paralelo a personas

------------

## ğŸ–¥ï¸ 5. Interfaz Web con Streamlit â€” streamlit_app.py

La UI incluye:

âœ”ï¸ Dos columnas principales

| Izquierda            | Derecha          |
| -------------------- | ---------------- |
| Personas + velocidad | YOLO componentes |

âœ”ï¸ Botones de control

- Iniciar
- Detener

âœ”ï¸ Sidebar editable

- Ãndice de cÃ¡mara
- Factor de calibraciÃ³n pixels_to_m

âœ”ï¸ ActualizaciÃ³n fluida sin parpadeo

Gracias a:

- last_person_img
- last_comp_img

Se actualiza solo si llega un nuevo frame, evitando â€œflashâ€.

![Prueba del Programa](https://github.com/yojan-maker/Proyecto/blob/main/Proyecto/Mediapipe_Yolo/yolo%201.jpeg?raw=true)

![Prueba con Multimetro](https://github.com/yojan-maker/Proyecto/blob/main/Proyecto/Mediapipe_Yolo/yolo%202.jpeg?raw=true)

![Prueba con RaspBerryPi](https://github.com/yojan-maker/Proyecto/blob/main/Proyecto/Mediapipe_Yolo/yolo%203.jpeg?raw=true)

![Prueba con Osciloscopio](https://github.com/yojan-maker/Proyecto/blob/main/Proyecto/Mediapipe_Yolo/yolo%204.jpeg?raw=true)

------------

## ğŸ§© 6. Scripts Auxiliares

### 6.1. Generador de clases â€” generate_class_names.py

Genera automÃ¡ticamente class_names.json segÃºn subcarpetas del dataset.

Ideal para:

- Clasificadores
- Keras
- ExportaciÃ³n dinÃ¡mica

### 6.2. train_classifier.py

Entrena un modelo CNN basado en MobileNetV2:

- Data augmentation
- EarlyStopping
- Checkpoints
- LR scheduler
- Exporta model.h5

### 6.3. utils_tracker.py

VersiÃ³n modular del CentroidTracker.

Incluye:

- Registro
- Deregistro
- Distancias
- Historial
- CÃ¡lculo de velocidad

------------

## ğŸ³ 7. DockerizaciÃ³n del Proyecto

El proyecto se ejecuta en cualquier servidor gracias al Dockerfile:

El archivo principal es:

âœ”ï¸ Dockerfile_mediapipe

Incluye:

ğŸ§© Base ligera:
    FROM python:3.10-slim

ğŸ—ï¸ InstalaciÃ³n de dependencias del sistema:

Se instalan:

- libgl1-mesa-glx â†’ OpenCV
- libglib2.0-0
- libgomp1 â†’ necesaria para YOLO

ğŸ§ª InstalaciÃ³n de dependencias Python:

    pip install --no-cache-dir -r requirements.txt

â–¶ï¸ Comando de ejecuciÃ³n:

    streamlit run streamlitapp.py --server.port=8501 --server.address=0.0.0.0

### Proceso de Dockerizacion

1. docker build
2. docker tag
3. docker push
4. subir imagen al registry

![Dockerizacion](https://github.com/yojan-maker/Proyecto/blob/main/Proyecto/Mediapipe_Yolo/dock1.jpeg?raw=true)

![Dockerizacion](https://github.com/yojan-maker/Proyecto/blob/main/Proyecto/Mediapipe_Yolo/dock3.jpeg?raw=true)

![Dockerizacion](https://github.com/yojan-maker/Proyecto/blob/main/Proyecto/Mediapipe_Yolo/dock4.jpeg?raw=true)

Dockerhub
https://hub.docker.com/r/yojancg/streamlit-yolo/tags

------------

## ğŸ§  8. Problemas Encontrados y Decisiones Tomadas

Este proyecto evolucionÃ³ con mÃºltiples pruebas:

### âŒ Primer problema: YOLO y mediapipe en el mismo hilo

Resultado â†’ se bloqueaba la cÃ¡mara.
SoluciÃ³n â†’ separar en hilos independientes.

### âŒ Segundo problema: Parpadeo en Streamlit

Causa â†’ Streamlit borra el widget al actualizarlo.
SoluciÃ³n â†’ mantener last_frame en memoria.

### âŒ Tercer problema: YOLO detectaba personas como multÃ­metros

Causa â†’ modelo con clases incorrectas.
SoluciÃ³n â†’ mejor dataset y anchors.

### âŒ Problema: pÃ©rdida de FPS

Causa â†’ procesamiento simultÃ¡neo y pesado
SoluciÃ³n â†’ Queue(maxsize=2)

------------

## ğŸ”„ 9. ExplicaciÃ³n Profunda de Concurrencia, Hilos, SemÃ¡foros y Mutex

### âœ” Hilos usados

| Hilo                | FunciÃ³n                               |
| ------------------- | ------------------------------------- |
| VideoCaptureThread  | captura la cÃ¡mara                     |
| PersonProcessor     | detecta personas, calcula velocidades |
| ComponentsProcessor | YOLO personalizado                    |

### âœ” Â¿DÃ³nde estÃ¡ la semaforizaciÃ³n?

En las colas Queue:

    frame_q_person = Queue(maxsize=2)
    frame_q_comp = Queue(maxsize=2)

Esa cola funciona como un semÃ¡foro:

- put() bloquea si estÃ¡ llena
- get() bloquea si estÃ¡ vacÃ­a

Lo que evita:

- condiciones de carrera
- frame duplicados
- saturaciÃ³n
- pÃ©rdida de sincronizaciÃ³n

### âœ” Â¿Se usÃ³ mutex?

SÃ­, implÃ­citamente.

Las colas de Python usan locking interno, por lo cual:

- un solo thread escribe
- un solo thread lee
- acceso atÃ³mico garantizado

---

## ConclusiÃ³n General del Proyecto

El desarrollo completo de este proyecto integrÃ³ de forma coherente y funcional diversas Ã¡reas de la ingenierÃ­a electrÃ³nica, visiÃ³n por computador, manejo de datos, programaciÃ³n concurrente y despliegue de aplicaciones web. A travÃ©s de las cuatro fases propuestas, se construyÃ³ una soluciÃ³n robusta, eficiente y totalmente operativa que cumple con los requerimientos planteados por la Universidad Santo TomÃ¡s.

En primer lugar, se logrÃ³ implementar un sistema de web scraping avanzado, capaz de adquirir de forma automatizada un volumen considerable de imÃ¡genes de elementos electrÃ³nicos. Este proceso incluyÃ³ el uso intencional de hilos, semÃ¡foros, exclusiÃ³n mutua y colas de tareas, garantizando la integridad del dataset, reduciendo tiempos de ejecuciÃ³n y evitando condiciones de carrera y bloqueos por parte de los servidores externos. El resultado fue una base de datos sÃ³lida y estructurada, acompaÃ±ada de metadatos completos que documentan su procedencia y estado.

En segundo lugar, se construyÃ³ un pipeline ETL profesional, responsable de la extracciÃ³n, depuraciÃ³n, validaciÃ³n, transformaciÃ³n y organizaciÃ³n de las imÃ¡genes. Este mÃ³dulo permitiÃ³ consolidar un dataset final consistente, depurado de duplicados, imÃ¡genes corruptas o irrelevantes, y estandarizado para su uso en algoritmos de clasificaciÃ³n. El proceso fue diseÃ±ado con una arquitectura escalable y multihilo, capaz de manejar miles de archivos con eficiencia.

En la tercera fase, se integraron dos sistemas de visiÃ³n por computador en tiempo real:

detecciÃ³n y seguimiento de personas con cÃ¡lculo de velocidad mediante tÃ©cnicas basadas en centroides,

detecciÃ³n de componentes electrÃ³nicos utilizando un modelo YOLO personalizado.

Ambos sistemas fueron unificados dentro de una arquitectura concurrente que permite procesar video en vivo de forma fluida y confiable, respetando los principios de sincronizaciÃ³n, paralelismo y estabilidad.

Finalmente, la totalidad de la soluciÃ³n fue empaquetada y desplegada como una aplicaciÃ³n web interactiva mediante Streamlit, permitiendo visualizar simultÃ¡neamente la detecciÃ³n de personas y componentes, asÃ­ como las mÃ©tricas de velocidad. El proceso incluyÃ³ la integraciÃ³n en un contenedor Docker completamente funcional y su publicaciÃ³n en DockerHub, otorgÃ¡ndole portabilidad, reproducibilidad y facilidad de ejecuciÃ³n en cualquier entorno.

Este proyecto representa un ejercicio completo de ingenierÃ­a aplicada, combinando conceptos avanzados de concurrencia, procesamiento de imÃ¡genes, administraciÃ³n de datos, aprendizaje automÃ¡tico y despliegue en la nube. El resultado final es una plataforma integral, modular, bien documentada y alineada con las necesidades tecnolÃ³gicas contemporÃ¡neas de la universidad.

## Autores y contribuciones 

â­ Autores y Contribuciones

- ğŸ‘¤ Autor Principal â€” Yojan Contreras
	- ContribuciÃ³n: 100% del desarrollo tÃ©cnico, implementaciÃ³n, documentaciÃ³n y despliegue del sistema.

- 1. Desarrollo del Web Scraping multihilo (Punto 1)

	- ImplementaciÃ³n del sistema completo de scraping con:

	- Hilos (threads)

	- SemÃ¡foros para limitar conexiones simultÃ¡neas

	- Locks (mutex) para evitar race conditions

	- Cola de tareas (producer-consumer)

	- ExtracciÃ³n masiva de miles de imÃ¡genes desde Bing Images.

	- Manejo complejo de Selenium, control de scroll, click en miniaturas, obtenciÃ³n de imÃ¡genes HD.

	- ImplementaciÃ³n avanzada del sistema de:

	- Descarga concurrente

	- Renombrado seguro

	- Estructura de carpetas por clase

	- Registro completo en metadata.csv

- 2. Limpieza, ValidaciÃ³n y ETL del Dataset (Punto 2)

	- CreaciÃ³n completa del pipeline ETL:

	- ExtracciÃ³n â†’ TransformaciÃ³n â†’ Carga

	- ValidaciÃ³n con Pillow para detectar imÃ¡genes corruptas.

	- EliminaciÃ³n masiva de duplicados vÃ­a hash SHA-256.

	- EstandarizaciÃ³n y normalizaciÃ³n del dataset.

	- Preprocesamiento con redimensionamiento y conversiÃ³n RGB.

	- OrganizaciÃ³n en carpetas preprocesadas y dataset dividido.

	- ConstrucciÃ³n estructurada de metadata_processed.csv.

- 3. Modelos de ClasificaciÃ³n y Velocidad en Tiempo Real (Punto 3)

	- ImplementaciÃ³n del sistema de:

	- DetecciÃ³n de personas

	- Seguimiento con Centroid Tracker

	- CÃ¡lculo de velocidad en m/s

	- IntegraciÃ³n de YOLO personalizado para detecciÃ³n de:

		- MultÃ­metro

		- Osciloscopio

		- Raspberry Pi

		- CreaciÃ³n de arquitectura multihilo:

		- Captura en tiempo real

		- Procesamiento en paralelo

		- Salida sincronizada para Streamlit

		- EliminaciÃ³n del parpadeo usando doble cola y Ãºltimo frame persistente.

- 4. Plataforma Web con Streamlit (Punto 4)

	- Desarrollo completo de la interfaz:

	- Vista de Personas + Velocidad

	- Vista de Componentes YOLO

	- Panel de configuraciÃ³n (sidebar)

	- IntegraciÃ³n del sistema multihilo con Streamlit.

	- Manejo profesional de estados (session_state) y eventos.

	- Debugging y reconstrucciÃ³n de errores.

- 5. ContenerizaciÃ³n y Despliegue en Docker

	- CreaciÃ³n del Dockerfile completo:

		- LibrerÃ­as del sistema

		- InstalaciÃ³n de requisitos

		- GestiÃ³n correcta del runtime

		- CorrecciÃ³n de errores de paquetes obsoletos en Debian.

		- ConstrucciÃ³n final del contenedor funcional.

		- PublicaciÃ³n en DockerHub.

		- ExplicaciÃ³n documentada del despliegue paso a paso.

- 6. DocumentaciÃ³n exhaustiva del proyecto

	- RedacciÃ³n del README completo, detallado y profesional:

	- ExplicaciÃ³n profunda de hilos, mutex, semÃ¡foros.

	- Arquitectura del sistema.

	- JustificaciÃ³n tÃ©cnica.

	- AnÃ¡lisis de problemas y soluciones.

	- Estructura del proyecto.

	- Instrucciones de ejecuciÃ³n e instalaciÃ³n.

---


ğŸ‘¤ Colaborador Secundario â€” Cristian Losada


ContribuciÃ³n: ParticipaciÃ³n limitada en la parte documental

- Cristian Losada realizÃ³ una contribuciÃ³n mucho y menor, enfocada Ãºnicamente en:

	- Escribir un fragmento final parcial del README **inconcluso**.

	- Parte **incompleta** de la explicaciÃ³n textual del proyecto.

- No participÃ³ en:

	- Desarrollo del cÃ³digo

	- ImplementaciÃ³n de scraping

	- Desarrollo del ETL

	- Entrenamiento o integraciÃ³n de modelos

	- ProgramaciÃ³n del sistema en tiempo real

	- ContenerizaciÃ³n con Docker

	- Despliegue de Streamlit
