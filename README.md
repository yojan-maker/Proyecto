# PUNTO 1 y 2 â€”  ExtracciÃ³n y TransformaciÃ³n de Datos (Web Scraping + ETL)

# 1. IntroducciÃ³n General

La **Universidad Santo TomÃ¡s** se encuentra en un proceso de modernizaciÃ³n tecnolÃ³gica, buscando optimizar sus flujos de trabajo mediante soluciones basadas en **inteligencia artificial**, **visiÃ³n por computador** y **automatizaciÃ³n**.

Dentro de este proceso, se solicitÃ³ el diseÃ±o e implementaciÃ³n de un sistema capaz de:

* Construir una **base de datos extensa** con imÃ¡genes de elementos de laboratorio de electrÃ³nica.
* Automatizar el proceso de adquisiciÃ³n mediante tÃ©cnicas de **web scraping**. 
* Utilizar **concurrencia** (hilos), **semÃ¡foros**, **exclusiÃ³n mutua** y **colas seguras** para incrementar el rendimiento.
* Generar **metadatos consistentes** para su posterior uso en modelos con MediaPipe.

---

Este informe documenta en profundidad la **arquitectura del *software***, los fundamentos teÃ³ricos empleados y las **decisiones tÃ©cnicas** que guiaron el desarrollo.

El Ã©nfasis estÃ¡ en la implementaciÃ³n de **hilos**, **semÃ¡foros**, **mutex** y **sincronizaciÃ³n concurrente**.

---
# 2. JustificaciÃ³n del uso de Web Scraping con Concurrencia

## 2.1. La necesidad de scraping masivo

Cada clase de objeto debÃ­a contar con **mÃ­nimo 200 imÃ¡genes**, y el proyecto incluÃ­a inicialmente **10 clases** (multÃ­metro, osciloscopio, protoboard, cautÃ­n, fuente de poder, generador de funciones, motor paso a paso, transformador, resistencia, capacitor).

Esto implicaba recolectar **2000 imÃ¡genes vÃ¡lidas**, no duplicadas, descargadas, verificadas y almacenadas en el menor tiempo posible.

El *scraping* secuencial se considerÃ³ inviable por las siguientes razones:
* **AltÃ­simos tiempos de espera** (latencia de red, en este caso mas de 10 horas para dos clases).
* Dependencia de redes externas lentas.
* Necesidad de **validar imÃ¡genes manualmente** (proceso lento).
* **Riesgo alto de bloqueo** por parte del motor de bÃºsqueda (por la alta frecuencia de peticiones desde un Ãºnico hilo).

> 

La **soluciÃ³n Ã³ptima** para cumplir con los requisitos de volumen y tiempo debÃ­a ser inherentemente **concurrente**.

---

## 3. Fundamentos TeÃ³ricos de Concurrencia Aplicados

Esta secciÃ³n profundiza en la teorÃ­a que fundamenta la implementaciÃ³n utilizada.
# 3.1. Hilos (Threads)

Los **hilos** (`Threads`) permiten ejecutar mÃºltiples tareas de forma **concurrente** dentro de un mismo proceso, compartiendo memoria, variables y archivos.

### AplicaciÃ³n en este Proyecto
En este proyecto de *web scraping* masivo:
* Cada hilo es un **consumidor** de la cola de URLs.
* Se encarga de descargar una imagen, verificarla, procesarla, guardarla y registrar sus metadatos.

### Ventajas de usar hilos en Web Scraping
El uso de hilos fue crÃ­tico debido a que el *scraping* es una tarea limitada por operaciones de Entrada/Salida (**I/O-bound**):

| Ventaja | DescripciÃ³n |
| :--- | :--- |
| **Alta latencia de red** | Mientras un hilo espera a que se complete una descarga de red, otros pueden avanzar. |
| **CPU poco utilizada** | El proceso estÃ¡ limitado por la I/O, no por procesamiento de CPU. |
| **Bajo consumo de memoria** | Comparado con la creaciÃ³n de mÃºltiples procesos independientes (*multiprocessing*). |
| **Simplicidad de estado** | Es mÃ¡s sencillo compartir y sincronizar el estado global (contador por clase, CSV de metadatos, cola de URLs). |

### JustificaciÃ³n 
El *scraping* es una tarea tÃ­picamente I/O-bound, lo cual se beneficia del modelo de hilos incluso con la presencia del **GIL (Global Interpreter Lock)** de Python, ya que:

* El **GIL se libera** durante operaciones de red que esperan datos.
* La descarga de imÃ¡genes no compite por tiempo de CPU.
* Los hilos se ejecutan de manera eficiente sin necesidad de recurrir a la complejidad del *multiprocessing*.

---

# 3.2. ExclusiÃ³n Mutua â€” Mutex / Lock

**Problema:** Los hilos comparten recursos sensibles, como:

* El archivo **`metadata.csv`** (para registrar los datos).
* Los **contadores de imÃ¡genes** por categorÃ­a (para nombrar archivos).
* Los Ã­ndices para nombres de archivos.
* La carpeta donde se guardan las imÃ¡genes.

Sin protecciÃ³n, aparece el riesgo de **condiciones de carrera** (*race conditions*).

### ğŸš¨ Ejemplo de CondiciÃ³n de Carrera real:

Dos hilos revisan simultÃ¡neamente cuÃ¡ntas imÃ¡genes lleva la categorÃ­a "multimeter":

```bash
Hilo 1 â†’ ve que hay 50
Hilo 2 â†’ ve que hay 50
Ambos deciden guardar la imagen como multimeter_00051.jpg
```
- Resultado: Se sobrescribe un archivo o se corrompe el dataset.

- SoluciÃ³n:

  - Se implementÃ³:
    ```bash
    counter_lock = threading.Lock()
    ```
  - Este mutex garantiza:

    - Acceso exclusivo a las secciones crÃ­ticas.

    - Escritura ordenada en metadata.csv.

    - Que solo un hilo manipule los contadores.

    - GeneraciÃ³n correcta de nombres de archivos.

    - Evitar duplicados generados por carreras.

  # 3.3. SemaforizaciÃ³n â€” Control de Conexiones SimultÃ¡neas

Los **SemÃ¡foros** se emplean para **limitar el nÃºmero de conexiones abiertas simultÃ¡neamente** a la red, actuando como un contador de permisos.

### ImplementaciÃ³n:
Se utilizÃ³ un semÃ¡foro para restringir cuÃ¡ntos hilos pueden estar descargando activamente en un momento dado:

```bash
download_semaphore = threading.Semaphore(MAX_SIMULTANEOUS_DOWNLOADS)
```

- Â¿Por quÃ© era necesario un SemÃ¡foro?

  - El semÃ¡foro es crucial para la robustez del scraper debido a los siguientes riesgos:

      - Bloqueo de IPs: Los servicios de imÃ¡genes (como Bing) bloquean o imponen CAPTCHAs a IPs que realizan descargas excesivas en paralelo en un corto perÃ­odo de tiempo.

      - PatrÃ³n sospechoso: Sin lÃ­mite, 8 hilos podrÃ­an generar 8 conexiones simultÃ¡neas cada segundo, lo que se identifica como un patrÃ³n de ataque o bot.

      - SaturaciÃ³n: El sistema podrÃ­a saturar la red local o el motor de bÃºsqueda, provocando timeouts continuos y un rendimiento inestable.

      - FunciÃ³n: El semÃ¡foro pone en espera a los hilos que exceden el lÃ­mite, asegurando que solo un nÃºmero controlado (MAX_SIMULTANEOUS_DOWNLOADS) acceda a los recursos de red a la vez.

  ### **CÃ³mo funciona**

    - Antes de descargar una imagen:
    ```bash
    download_semaphore.acquire()
    ```
    Cuando finaliza:
    ```bash
    download_semaphore.release()
    ```
  ### **Analizando el impacto**

- Al limitar a 5 conexiones simultÃ¡neas se logrÃ³:

  - Mantener trÃ¡fico estable.

  - Evitar bloqueos por parte del servidor.

  - Permitir a los demÃ¡s hilos continuar descargando en paralelo.

# 3.4. Cola de Tareas â€” Productor/Consumidor

La arquitectura se diseÃ±Ã³ como:

- Productor

  - Produce URLs obtenidas con Selenium.

  - Las inserta en la cola:
```bash
download_queue.put((url, label))
```
- Consumidores

  - Hilos que obtienen tareas:
```bash
item = download_queue.get()
```
  - Procesan la descarga, verificaciÃ³n, y guardado.

 ## 4. Arquitectura del Sistema Desarrollado

La arquitectura final del sistema de extracciÃ³n y descarga se estructurÃ³ en los siguientes **mÃ³dulos** principales:

---

### 1. MÃ³dulo Selenium

Este mÃ³dulo es el Productor de tareas, encargado de la extracciÃ³n de las URLs objetivo.

* **FunciÃ³n:** Extrae cientos de URLs tanto de miniaturas como de las imÃ¡genes de alta definiciÃ³n (reales).
* **Mecanismo:** Se desplazÃ³ dinÃ¡micamente por la plataforma **Bing Images**.
* **TÃ©cnica Clave:** Aprovecha el evento de **click en las miniaturas** para exponer y obtener las URLs de las imÃ¡genes en calidad HD.

---

### 2. MÃ³dulo de Cola de URLs

ActÃºa como el buffer central entre los mÃ³dulos de extracciÃ³n y los de descarga.

* **FunciÃ³n Principal:** Administra el **backlog de trabajo** (las URLs extraÃ­das).
* **Control de Flujo:** Controla el ritmo y el flujo de las tareas que serÃ¡n entregadas a los **hilos consumidores**.

---

### 3. MÃ³dulo Multithreading

Este mÃ³dulo implementa la concurrencia para la descarga eficiente de archivos.

* **FunciÃ³n:** Ejecuta **mÃºltiples descargas en paralelo** para maximizar el rendimiento.
* **Principio:** Cada hilo de trabajo opera de forma **independiente y segura** al procesar su tarea asignada.

---

### 4. Gestores de SincronizaciÃ³n

Componentes esenciales para garantizar la seguridad y el orden en el entorno concurrente.

* **`Lock`:** Se utiliza para **proteger datos compartidos** de condiciones de carrera (ej., al actualizar un contador global).
* **`SemÃ¡foro`:** Se emplea para **controlar las conexiones simultÃ¡neas** a la fuente externa, evitando la sobrecarga o el bloqueo por parte del servidor de destino.

---

### 5. MÃ³dulo de Metadatos

Asegura la trazabilidad y la integridad de los datos descargados.

* **Almacenamiento:** Guarda la informaciÃ³n esencial de cada imagen: **nombre, tamaÃ±o, URL y el hash SHA256**.
* **Beneficios:**
    * Asegura la **reproducibilidad** del proceso.
    * Permite la **detecciÃ³n futura de duplicados** de manera infalible.

---

### 6. Depuradores Posteriores

Scripts complementarios ejecutados tras la finalizaciÃ³n de las descargas.

* **FunciÃ³n 1:** **EliminaciÃ³n de imÃ¡genes corruptas** o incompletas.
* **FunciÃ³n 2:** Realiza la **deduplicaciÃ³n** final por hash (`SHA256`) utilizando scripts de apoyo.

## 5. Problemas Reales Durante el Desarrollo y Soluciones

Esta secciÃ³n detalla los principales obstÃ¡culos encontrados durante la implementaciÃ³n y las soluciones tÃ©cnicas aplicadas, lo que demuestra el cumplimiento de objetivos y el aprendizaje tÃ©cnico adquirido.

---

## 5.1. Descarga de imÃ¡genes irrelevantes

El principal desafÃ­o en la fase de extracciÃ³n fue la **baja precisiÃ³n** de los resultados de bÃºsqueda de la fuente (`Bing Images`).

* **Problema Real:** Al buscar un tÃ©rmino tÃ©cnico y especÃ­fico como **"multimeter"** (multÃ­metro), la herramienta de bÃºsqueda tendÃ­a a devolver imÃ¡genes contextualmente irrelevantes, tales como sillas, escritorios o fotografÃ­as de personas utilizando el multÃ­metro, en lugar del dispositivo en sÃ­.
* **Soluciones Aplicadas:**
    1.  **Ajuste del Keyword:** Se implementÃ³ una estrategia de **ajuste fino de los tÃ©rminos de bÃºsqueda** para intentar acotar los resultados.
    2.  **Curado en Limpieza Posterior:** Se asumiÃ³ una fase de **curado manual o semiautomÃ¡tico** como parte del proceso de limpieza posterior para descartar imÃ¡genes no deseadas.
    3.  **Balance de Dataset:** Posteriormente, para diversificar y mejorar la calidad del conjunto de datos, se aÃ±adiÃ³ el tÃ©rmino **"transistor"** a la lista de keywords, buscando **balancear** la tipologÃ­a de las imÃ¡genes.

---

### 5.2. Tiempo excesivo de ExtracciÃ³n (>10 horas)

La optimizaciÃ³n del tiempo de ejecuciÃ³n fue crÃ­tica, ya que el proceso inicial consumÃ­a una cantidad de tiempo inaceptable para la escala de datos requerida.

* **Problema Real:** La extracciÃ³n de aproximadamente **2000 imÃ¡genes limpias** requiriÃ³ un tiempo de ejecuciÃ³n excesivamente largo, lo que afectÃ³ la productividad y la iteraciÃ³n del desarrollo:
    * **5 horas** con Firefox (El proceso fallÃ³ por errores de perfil del navegador).
    * **MÃ¡s de 10 horas en total** para completar las extracciones de solo dos clases con la implementaciÃ³n inicial de **Selenium**.
* **Intentos de SoluciÃ³n Fallidos:**
    * Se intentÃ³ alternar el *driver* de Selenium entre **Chromium** y **Firefox** para buscar una ganancia de rendimiento, sin Ã©xito significativo.
    * Se evaluaron mÃ©todos externos como la librerÃ­a **`bing_image_downloader`**, pero se descartaron por falta de flexibilidad o control.
* **SoluciÃ³n Final Adoptada (CombinaciÃ³n de Enfoques):**
    1.  **Scraping Multithreading:** Se implementÃ³ y optimizÃ³ un sistema de **scraping concurrente** utilizando **`multithreading`** para manejar la mayorÃ­a de las descargas en paralelo.
    2.  **Herramienta Alternativa EspecÃ­fica:** Se utilizÃ³ una **herramienta alternativa especÃ­fica** para la extracciÃ³n del subconjunto de imÃ¡genes de **"transistores"**, aprovechando su eficiencia para esa tarea concreta.
    3.  **Limpieza Posterior AutomÃ¡tica:** La dependencia en una **limpieza posterior automÃ¡tica** se incrementÃ³ para manejar la escala de datos extraÃ­dos rÃ¡pidamente, compensando la velocidad de extracciÃ³n con un proceso de filtrado robusto.

### 5.3. EliminaciÃ³n masiva â€” PÃ©rdida del 40â€“60% de imÃ¡genes

DespuÃ©s del dedupe por hash:
  ```bash
  Eliminados: 1189
  ```
- Causas:

  - ImÃ¡genes duplicadas en miniaturas/HD.

  - Servidores devolvÃ­an la misma imagen con URLs diferentes.

  - Historias de cache del buscador.

- Resultado final:

  - Todas las carpetas quedaron con mÃ¡s de 100 imÃ¡genes vÃ¡lidas.
  - Aunque no se alcanzÃ³ exactamente 200 por clase, el dataset es consistente y limpio.

  ## 7. Conclusiones del Punto 1: Logros y Aprendizajes

La ejecuciÃ³n exitosa de este proyecto de construcciÃ³n de dataset y sistema de scraping condujo a los siguientes logros y aprendizajes clave:

---

### Logros del Proyecto

* **ConstrucciÃ³n de un Dataset Personalizado para el Laboratorio:** Se logrÃ³ crear un dataset de alta calidad, curado y especÃ­fico, con una cantidad de mÃ¡s de 100 imÃ¡genes por clase despuÃ©s de la fase de limpieza y depuraciÃ³n.
* **Desarrollo de un Sistema de Scraping Robusto y Realista:** Se diseÃ±Ã³ y codificÃ³ un sistema de extracciÃ³n que demostrÃ³ ser capaz de realizar trabajo intensivo de larga duraciÃ³n, resolviendo desafÃ­os reales de estabilidad y gestiÃ³n de errores.
* **ImplementaciÃ³n de TÃ©cnicas Avanzadas de Concurrencia:** Se aplicaron con Ã©xito principios de multithreading y sincronizaciÃ³n (Lock, Semaphore) en una aplicaciÃ³n real, con impactos tangibles en la reducciÃ³n del tiempo de procesamiento.

---

### Aprendizajes Clave

* **LÃ­mites y Fallos Comunes del Scraping:** Se obtuvo una experiencia prÃ¡ctica profunda en el manejo y mitigaciÃ³n de problemas intrÃ­nsecos al web scraping a gran escala, incluyendo:
    * **Bloqueos de IP:** Estrategias para evadir o manejar las restricciones del servidor fuente.
    * **ImÃ¡genes Ruidosas:** GestiÃ³n de imÃ¡genes con contenido contextual irrelevante.
    * **Contenidos No Relevantes:** Filtrado efectivo de resultados que no cumplen con los requisitos de la clase (ej., errores de keyword).
    * **Duplicados Masivos:** ImplementaciÃ³n de hashing (SHA256) para la detecciÃ³n y eliminaciÃ³n eficiente.

* **GeneraciÃ³n de una Arquitectura Escalable:** El diseÃ±o modular y desacoplado del sistema sentÃ³ las bases para la escalabilidad y la integraciÃ³n futura con mÃ³dulos de Machine Learning para los siguientes objetivos del proyecto:
    * ClasificaciÃ³n con MediaPipe.
    * Reconocimiento de elementos.
    * ImplementaciÃ³n del sistema final en Streamlit.

  ---

## ğŸ“ Estructura del proyecto: tree + explicaciÃ³n completa

A continuaciÃ³n se muestra la estructura final del proyecto de Web Scraping con Python, enriquecida con una explicaciÃ³n exhaustiva de cada componente:

**webscrapping/**
* **venv/**
    * ... (Entorno virtual con dependencias)
* **dataset/**
    * [Carpetas de Clases]
        * breadboard/
        * capacitor_electronic_component/
        * diode_electronic_component/
        * function_generator/
        * multimeter/
        * oscilloscope/
        * resistor_electronic_component/
        * soldering_iron/
        * stepper_motor/
        * transistor_electronic_component/
* **metadata/**
    * metadata.csv (Registro formal y trazabilidad del dataset)
* **Archivos Ejecutables y Scripts**
    * scraper\_dataset.py (Scraper PRINCIPAL: Multihilo, SemÃ¡foros, Mutex)
    * fast\_download\_transistor.py (Script alterno/de emergencia)
    * check\_corrupt.py (Script para detectar y registrar imÃ¡genes daÃ±adas)
    * dedupe\_by\_hash.py (Script para eliminaciÃ³n masiva de duplicados por hash SHA-256)
    * README.md (DocumentaciÃ³n principal del proyecto)
  * **Dockerfile**
  * **requirements.txt**

## ğŸ§© ExplicaciÃ³n de las Carpetas y Archivos Principales

A continuaciÃ³n se detalla la funciÃ³n de cada directorio y archivo clave dentro de la estructura del proyecto.

---

### 1. `venv/` â€” Entorno Virtual ğŸ§ª

Este directorio es esencial para la gestiÃ³n de dependencias del proyecto. 

* **FunciÃ³n Principal:** Contiene todas las **dependencias de Python** de forma aislada del sistema operativo principal.
* **PropÃ³sito:**
    * **Evita conflictos de versiones** con librerÃ­as o paquetes instalados globalmente en el sistema.
    * Aloja librerÃ­as especÃ­ficas utilizadas en el proyecto, como **`requests`**, **`Pillow`**, **`bing_image_downloader`**, **`beautifulsoup4`**, etc.
    * **Garantiza la portabilidad:** Asegura que cualquier desarrollador que ejecute el proyecto tenga **exactamente el mismo entorno** de trabajo.
* **Estatus:** Es una carpeta indispensable para el desarrollo profesional y reproducible de proyectos en Python.

---

### 2. `dataset/` â€” Carpetas con las ImÃ¡genes Finales ğŸ’¾

Este directorio almacena la salida principal del proceso de *scraping* y limpieza: el conjunto de datos final.

* **FunciÃ³n Principal:** Contiene todas las **clases (categorÃ­as)** que componen el *dataset*.
* **Estructura Interna:** Cada clase se representa mediante una subcarpeta dentro de `dataset/`.
* **Nomenclatura:** Las carpetas de clase tienen un **nombre normalizado** para facilitar el procesamiento posterior por modelos de Machine Learning.

- Ejemplos:

  - breadboard/

  - multimeter/

  - transistor_electronic_component/

  Cada carpeta dentro de `dataset/` contiene las siguientes caracterÃ­sticas despuÃ©s del proceso de curado:

* **ImÃ¡genes VÃ¡lidas:** Solo incluye imÃ¡genes que han pasado el proceso de deduplicaciÃ³n (sin duplicados).
* **ImÃ¡genes NO Corruptas:** Todos los archivos han sido verificados y garantizan su integridad estructural.
* **Cantidad Final:** **MÃ¡s de 100 imÃ¡genes por clase** despuÃ©s de la limpieza.

> **Nota:** Aunque el objetivo inicial era de 200 imÃ¡genes por clase, los desafÃ­os inherentes al *scraping* (problemas de precisiÃ³n en Bing, el exceso de imÃ¡genes basura y la enorme cantidad de duplicados) redujeron el total final. Esta limitaciÃ³n cuantitativa se justifica y explica detalladamente en el **README tÃ©cnico** del proyecto.

---

### 3. `metadata/metadata.csv` â€” Registro Formal del Dataset ğŸ“„

Este archivo es crucial para la **trazabilidad, auditorÃ­a y reproducibilidad** del conjunto de datos. En proyectos serios de *Machine Learning* y anÃ¡lisis de datos, el registro formal del origen y estado de cada muestra es un requisito clave.



**Campos TÃ­picos del `metadata.csv`:**

| Campo | DescripciÃ³n |
| :--- | :--- |
| `image_path` | La ruta relativa al archivo dentro de la carpeta `dataset/`. |
| `class` | La categorÃ­a o etiqueta a la que pertenece la imagen (ej. 'multimeter', 'transistor'). |
| `resolution` | La resoluciÃ³n de la imagen (ej. '640x480'). |
| `file_size` | El tamaÃ±o del archivo en bytes. |
| `hash_sha256` | El **hash criptogrÃ¡fico SHA256**, fundamental para la detecciÃ³n de duplicados y la verificaciÃ³n de integridad. |
| `is_corrupt` | Indicador booleano que registra si la imagen fue marcada como corrupta (deberÃ­a ser **False** para todas las entradas finales). |
| `duplicate_of` | Si es un duplicado, registra el `image_path` del archivo original que se conservÃ³. |

## 4. `scraper_dataset.py` â€” Scraper PRINCIPAL Multihilo (con SemÃ¡foros y Mutex)

Este script es el **archivo mÃ¡s importante y central** de todo el proyecto, conteniendo la lÃ³gica de concurrencia y la gestiÃ³n robusta de errores para la descarga de imÃ¡genes.

---

### Funcionalidades Clave y TÃ©cnicas de Concurrencia

El script implementa tÃ©cnicas avanzadas de programaciÃ³n concurrente para optimizar el rendimiento y garantizar la integridad de los datos:

* **Uso de Threads (Hilos):**
    * **PropÃ³sito:** Se utilizan para ejecutar la descarga de **mÃºltiples imÃ¡genes en paralelo**. 
    * **Impacto:** Sin la concurrencia, el proceso de *scraping* habrÃ­a tardado un estimado de **40 a 60 horas**.

* **Uso de SemÃ¡foros (`Semaphore`):**
    * **FunciÃ³n:** Se implementa un **semÃ¡foro** para **limitar el nÃºmero de descargas simultÃ¡neas** a un valor seguro (ejemplo: `semaphore = threading.Semaphore(8)`).
    * **Beneficios:**
        * Evita **bans temporales** por parte de la fuente (`Bing Images`).
        * Previene **errores por saturaciÃ³n** del servidor de destino.
        * Minimiza **timeouts masivos** y el riesgo de saturar la CPU o el ancho de banda local.

* **Uso de Mutex (`Lock`):**
    * **Necesidad:** El mutex (o `Lock`) es necesario porque, aunque las imÃ¡genes se descargan en paralelo, **varios hilos deben escribir simultÃ¡neamente** en recursos compartidos, como:
        * El archivo de registro de metadatos (`metadata.csv`).
        * **Contadores globales** de progreso o errores.
    * **Resultado:** El uso del mutex **evita *race conditions*** (condiciones de carrera) y previene la **corrupciÃ³n** del archivo CSV, garantizando la escritura atÃ³mica de los datos.

---

### GestiÃ³n de Errores y Almacenamiento

El script garantiza la fiabilidad del proceso de descarga mediante control de calidad y robustez:

* **Descarga con Control de Errores Robusto:**
    * **Manejo de Timeouts:** Implementa estrategias de reintento ante fallos de conexiÃ³n o tiempos de espera agotados.
    * **Retry AutomÃ¡tico:** Intenta automÃ¡ticamente la descarga un nÃºmero predefinido de veces antes de marcar una tarea como fallida.
    * **SanitizaciÃ³n del Nombre del Archivo:** Procesa y limpia el nombre del archivo para asegurar la compatibilidad con diferentes sistemas operativos.
    * **VerificaciÃ³n de Contenido:** Valida que el archivo descargado sea efectivamente una imagen (ej., contenido tipo `image/jpeg`, `image/png`), descartando posibles archivos HTML o corruptos.

* **Guardado y OrganizaciÃ³n:** Guarda cada imagen en su **carpeta de clase correspondiente** dentro del directorio `dataset/`, manteniendo la estructura organizada.

### 5. `fast_download_transistor.py` â€” Script Alterno de Emergencia ğŸš€

Este script fue desarrollado como una **soluciÃ³n de contingencia** para mitigar los problemas de eficiencia y precisiÃ³n del *scraper* principal en clases problemÃ¡ticas.

* **MotivaciÃ³n:** Se creÃ³ debido a:
    * El tiempo excesivo de ejecuciÃ³n del *scraper* principal (**mÃ¡s de 10 horas**).
    * El fallo en completar el objetivo de 200 imÃ¡genes en algunas clases.
    * La alta tasa de **imÃ¡genes irrelevantes** (sillas, autos, etc.) devueltas por Bing.
    * El componente **"transistor"** fue particularmente problemÃ¡tico en la extracciÃ³n.

* **ImplementaciÃ³n:** Utiliza la librerÃ­a **`bing_image_downloader`**, pero requiriÃ³ una **modificaciÃ³n interna del mÃ³dulo** debido a:
    * Un **bug** relacionado con la funciÃ³n `Path.isdir` en el entorno de desarrollo.
    * La necesidad de **adaptar el flujo de descarga** para integrarlo con la estructura de carpetas del proyecto.

* **Uso:** Solo se empleÃ³ una vez para **completar una clase puntual** (la de transistores) y balancear el *dataset*.

---

### 6. `check_corrupt.py` â€” Script para Detectar ImÃ¡genes DaÃ±adas ğŸ›¡ï¸

Este script de post-procesamiento garantiza la **integridad y usabilidad** de todos los archivos descargados.

* **Mecanismo de VerificaciÃ³n:** Revisa iterativamente cada archivo dentro del directorio `dataset/`.
    * **Proceso:** Intenta abrir la imagen utilizando la librerÃ­a **PIL (Pillow)**.
    * **AcciÃ³n:** Si la apertura falla, la imagen es marcada como **corrupta** y el estado se **registra en `metadata.csv`**. Opcionalmente, el script puede ser configurado para eliminar el archivo fÃ­sicamente.

* **Importancia CrÃ­tica:** Este script fue **crucial** porque:
    * Bing entregÃ³ una cantidad significativamente alta de **imÃ¡genes corruptas** o incompletas.
    * Se detectaron casos de archivos que eran realmente **cÃ³digo HTML disfrazado de JPG** (un error comÃºn de *scraping*).

---

### 7. `dedupe_by_hash.py` â€” EliminaciÃ³n Masiva de Duplicados âš™ï¸

Este script asegura la **unicidad** del *dataset*, un paso fundamental para evitar el sesgo en el entrenamiento de modelos de *Machine Learning*.

* **Proceso Central:**
    * **CÃ¡lculo de Hash:** Calcula el **hash SHA-256** de cada imagen. Esta es la tÃ©cnica mÃ¡s robusta y **garantiza detectar duplicados** incluso si los archivos tienen nombres o metadatos distintos. 
    * **EliminaciÃ³n:** **Elimina automÃ¡ticamente los duplicados reales**. En la ejecuciÃ³n del proyecto, el resultado fue: **Eliminados: 1189** archivos.

* **JustificaciÃ³n de Duplicados:** La alta tasa de duplicados es normal debido a:
    * La repeticiÃ³n masiva de contenido por parte de la fuente (`Bing`).
    * La similitud entre las clases del *dataset*.
    * La tendencia del buscador a devolver **clones reescalados** de la misma imagen.

* **Registro:** **Actualiza el `metadata.csv`**, marcando cuÃ¡l archivo fue duplicado de cuÃ¡l, manteniendo un registro de la limpieza.

![Image](https://github.com/user-attachments/assets/87457fb1-c937-48c2-b33d-3907dcc1ac2c)
>- Carpetas
---

![Image](https://github.com/user-attachments/assets/f716ea5b-7411-4878-80f3-75370a5ab821)
>- Dataset luego del primer web scrapping (sin limpieza)
---


![Image](https://github.com/user-attachments/assets/9ed39431-7098-4396-848e-860c054e8628)
>- VerificaciÃ³n imagenes corruptas
---

![Image](https://github.com/user-attachments/assets/f1d3aa2e-0535-4a78-ab7a-7c0679a83069)
>- Limpieza de imagenes 
---
![Image](https://github.com/user-attachments/assets/7a29297c-70a9-456e-8e5b-2bf1c23a2d70)
>- Limpieza semantica de imagenes ejemplo 1
---

![Image](https://github.com/user-attachments/assets/e6d7a427-5322-43e7-8d54-0ef314cc91fc)
>- Limpieza semantica de imagenes ejemplo 2
---

![Image](https://github.com/user-attachments/assets/3f3d7489-9a38-4b8d-ad4f-1af62686d606)
>- Limpieza semantica de imagenes ejemplo 3
---

![Image](https://github.com/user-attachments/assets/e5b0c03b-132c-475b-97d4-8f8d0a91936d)
>- Cantidad de imagenes despues de la limpieza
---

![Image](https://github.com/user-attachments/assets/80ca9f7a-c417-40f2-b8ef-f4cca9ddaeec)
>- Cantidad de imagenes despues de un nuevo web scrapping y limpieza
---


![Image](https://github.com/user-attachments/assets/3f6283f9-6d0e-4a83-a686-0a926118ed67)
>- Redimension de imÃ¡genes y conteo final
---

# Punto 3 - Sistema de DetecciÃ³n en Tiempo Real con Streamlit, YOLO, Seguimiento de Velocidad y Docker ğŸ³

En este punto  se integra un sistema completo para visiÃ³n artificial en tiempo real, combinando:

- DetecciÃ³n de personas
- CÃ¡lculo de velocidad por seguimiento con Centroid Tracking
- DetecciÃ³n de componentes electrÃ³nicos (osciloscopio, multÃ­metro, raspberryâ€¦) con YOLO personalizado
- Procesamiento paralelo (multithreading) con semaforizaciÃ³n natural usando colas
- Interfaz web en tiempo real desarrollada en Streamlit
- ContenedorizaciÃ³n con Docker
- Entrenamiento de un clasificador CNN
- GeneraciÃ³n automÃ¡tica de clases

------------

## ğŸ—ï¸ 1. Arquitectura General del Proyecto

El sistema se divide en mÃ³dulos independientes que cooperan:    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Streamlit (Frontend)     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
            ActualizaciÃ³n UI
                   â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚        Procesos              â”‚
    â”‚  (Threads independientes)    â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚              â”‚               â”‚
    â–¼              â–¼               â–¼
    Captura     Personas         Componentes
      |        (Tracking)           (YOLO)
      |             |                |
      â””â”€â”€â”€â”€â”€â”€â–º Cola Q â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Cada mÃ³dulo corre en un hilo separado, sincronizado mediante queues, que funcionan como buffers que evitan bloqueos y regulan el acceso concurrente (semaforizaciÃ³n implÃ­cita).
