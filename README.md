# PUNTO 1 y 2 ‚Äî  Extracci√≥n y Transformaci√≥n de Datos (Web Scraping + ETL)

# 1. Introducci√≥n General

La **Universidad Santo Tom√°s** se encuentra en un proceso de modernizaci√≥n tecnol√≥gica, buscando optimizar sus flujos de trabajo mediante soluciones basadas en **inteligencia artificial**, **visi√≥n por computador** y **automatizaci√≥n**.

Dentro de este proceso, se solicit√≥ el dise√±o e implementaci√≥n de un sistema capaz de:

* Construir una **base de datos extensa** con im√°genes de elementos de laboratorio de electr√≥nica.
* Automatizar el proceso de adquisici√≥n mediante t√©cnicas de **web scraping**. 
* Utilizar **concurrencia** (hilos), **sem√°foros**, **exclusi√≥n mutua** y **colas seguras** para incrementar el rendimiento.
* Generar **metadatos consistentes** para su posterior uso en modelos con MediaPipe.

---

Este informe documenta en profundidad la **arquitectura del *software***, los fundamentos te√≥ricos empleados y las **decisiones t√©cnicas** que guiaron el desarrollo.

El √©nfasis est√° en la implementaci√≥n de **hilos**, **sem√°foros**, **mutex** y **sincronizaci√≥n concurrente**.

---
# 2. Justificaci√≥n del uso de Web Scraping con Concurrencia

## 2.1. La necesidad de scraping masivo

Cada clase de objeto deb√≠a contar con **m√≠nimo 200 im√°genes**, y el proyecto inclu√≠a inicialmente **10 clases** (mult√≠metro, osciloscopio, protoboard, caut√≠n, fuente de poder, generador de funciones, motor paso a paso, transformador, resistencia, capacitor).

Esto implicaba recolectar **2000 im√°genes v√°lidas**, no duplicadas, descargadas, verificadas y almacenadas en el menor tiempo posible.

El *scraping* secuencial se consider√≥ inviable por las siguientes razones:
* **Alt√≠simos tiempos de espera** (latencia de red, en este caso mas de 10 horas para dos clases).
* Dependencia de redes externas lentas.
* Necesidad de **validar im√°genes manualmente** (proceso lento).
* **Riesgo alto de bloqueo** por parte del motor de b√∫squeda (por la alta frecuencia de peticiones desde un √∫nico hilo).

> 

La **soluci√≥n √≥ptima** para cumplir con los requisitos de volumen y tiempo deb√≠a ser inherentemente **concurrente**.

---

## 3. Fundamentos Te√≥ricos de Concurrencia Aplicados

Esta secci√≥n profundiza en la teor√≠a que fundamenta la implementaci√≥n utilizada.
# 3.1. Hilos (Threads)

Los **hilos** (`Threads`) permiten ejecutar m√∫ltiples tareas de forma **concurrente** dentro de un mismo proceso, compartiendo memoria, variables y archivos.

### Aplicaci√≥n en este Proyecto
En este proyecto de *web scraping* masivo:
* Cada hilo es un **consumidor** de la cola de URLs.
* Se encarga de descargar una imagen, verificarla, procesarla, guardarla y registrar sus metadatos.

### Ventajas de usar hilos en Web Scraping
El uso de hilos fue cr√≠tico debido a que el *scraping* es una tarea limitada por operaciones de Entrada/Salida (**I/O-bound**):

| Ventaja | Descripci√≥n |
| :--- | :--- |
| **Alta latencia de red** | Mientras un hilo espera a que se complete una descarga de red, otros pueden avanzar. |
| **CPU poco utilizada** | El proceso est√° limitado por la I/O, no por procesamiento de CPU. |
| **Bajo consumo de memoria** | Comparado con la creaci√≥n de m√∫ltiples procesos independientes (*multiprocessing*). |
| **Simplicidad de estado** | Es m√°s sencillo compartir y sincronizar el estado global (contador por clase, CSV de metadatos, cola de URLs). |

### Justificaci√≥n 
El *scraping* es una tarea t√≠picamente I/O-bound, lo cual se beneficia del modelo de hilos incluso con la presencia del **GIL (Global Interpreter Lock)** de Python, ya que:

* El **GIL se libera** durante operaciones de red que esperan datos.
* La descarga de im√°genes no compite por tiempo de CPU.
* Los hilos se ejecutan de manera eficiente sin necesidad de recurrir a la complejidad del *multiprocessing*.

---

# 3.2. Exclusi√≥n Mutua ‚Äî Mutex / Lock

**Problema:** Los hilos comparten recursos sensibles, como:

* El archivo **`metadata.csv`** (para registrar los datos).
* Los **contadores de im√°genes** por categor√≠a (para nombrar archivos).
* Los √≠ndices para nombres de archivos.
* La carpeta donde se guardan las im√°genes.

Sin protecci√≥n, aparece el riesgo de **condiciones de carrera** (*race conditions*).

### üö® Ejemplo de Condici√≥n de Carrera real:

Dos hilos revisan simult√°neamente cu√°ntas im√°genes lleva la categor√≠a "multimeter":

```bash
Hilo 1 ‚Üí ve que hay 50
Hilo 2 ‚Üí ve que hay 50
Ambos deciden guardar la imagen como multimeter_00051.jpg
```
- Resultado: Se sobrescribe un archivo o se corrompe el dataset.

- Soluci√≥n:

  - Se implement√≥:
    ```bash
    counter_lock = threading.Lock()
    ```
  - Este mutex garantiza:

    - Acceso exclusivo a las secciones cr√≠ticas.

    - Escritura ordenada en metadata.csv.

    - Que solo un hilo manipule los contadores.

    - Generaci√≥n correcta de nombres de archivos.

    - Evitar duplicados generados por carreras.

  # 3.3. Semaforizaci√≥n ‚Äî Control de Conexiones Simult√°neas

Los **Sem√°foros** se emplean para **limitar el n√∫mero de conexiones abiertas simult√°neamente** a la red, actuando como un contador de permisos.

### Implementaci√≥n:
Se utiliz√≥ un sem√°foro para restringir cu√°ntos hilos pueden estar descargando activamente en un momento dado:

```bash
download_semaphore = threading.Semaphore(MAX_SIMULTANEOUS_DOWNLOADS)
```

- ¬øPor qu√© era necesario un Sem√°foro?

  - El sem√°foro es crucial para la robustez del scraper debido a los siguientes riesgos:

      - Bloqueo de IPs: Los servicios de im√°genes (como Bing) bloquean o imponen CAPTCHAs a IPs que realizan descargas excesivas en paralelo en un corto per√≠odo de tiempo.

      - Patr√≥n sospechoso: Sin l√≠mite, 8 hilos podr√≠an generar 8 conexiones simult√°neas cada segundo, lo que se identifica como un patr√≥n de ataque o bot.

      - Saturaci√≥n: El sistema podr√≠a saturar la red local o el motor de b√∫squeda, provocando timeouts continuos y un rendimiento inestable.

      - Funci√≥n: El sem√°foro pone en espera a los hilos que exceden el l√≠mite, asegurando que solo un n√∫mero controlado (MAX_SIMULTANEOUS_DOWNLOADS) acceda a los recursos de red a la vez.

  ### **C√≥mo funciona**

    - Antes de descargar una imagen:
    ```bash
    download_semaphore.acquire()
    ```
    Cuando finaliza:
    ```bash
    download_semaphore.release()
    ```
  ### **Analizando el impacto**

- Al limitar a 5 conexiones simult√°neas se logr√≥:

  - Mantener tr√°fico estable.

  - Evitar bloqueos por parte del servidor.

  - Permitir a los dem√°s hilos continuar descargando en paralelo.

# 3.4. Cola de Tareas ‚Äî Productor/Consumidor

La arquitectura se dise√±√≥ como:

- Productor

  - Produce URLs obtenidas con Selenium.

  - Las inserta en la cola:
```bash
download_queue.put((url, label))
```
- Consumidores

  - Hilos que obtienen tareas:
```bash
item = download_queue.get()
```
  - Procesan la descarga, verificaci√≥n, y guardado.

 ## 4. Arquitectura del Sistema Desarrollado

La arquitectura final del sistema de extracci√≥n y descarga se estructur√≥ en los siguientes **m√≥dulos** principales:

---

### 1. M√≥dulo Selenium

Este m√≥dulo es el Productor de tareas, encargado de la extracci√≥n de las URLs objetivo.

* **Funci√≥n:** Extrae cientos de URLs tanto de miniaturas como de las im√°genes de alta definici√≥n (reales).
* **Mecanismo:** Se desplaz√≥ din√°micamente por la plataforma **Bing Images**.
* **T√©cnica Clave:** Aprovecha el evento de **click en las miniaturas** para exponer y obtener las URLs de las im√°genes en calidad HD.

---

### 2. M√≥dulo de Cola de URLs

Act√∫a como el buffer central entre los m√≥dulos de extracci√≥n y los de descarga.

* **Funci√≥n Principal:** Administra el **backlog de trabajo** (las URLs extra√≠das).
* **Control de Flujo:** Controla el ritmo y el flujo de las tareas que ser√°n entregadas a los **hilos consumidores**.

---

### 3. M√≥dulo Multithreading

Este m√≥dulo implementa la concurrencia para la descarga eficiente de archivos.

* **Funci√≥n:** Ejecuta **m√∫ltiples descargas en paralelo** para maximizar el rendimiento.
* **Principio:** Cada hilo de trabajo opera de forma **independiente y segura** al procesar su tarea asignada.

---

### 4. Gestores de Sincronizaci√≥n

Componentes esenciales para garantizar la seguridad y el orden en el entorno concurrente.

* **`Lock`:** Se utiliza para **proteger datos compartidos** de condiciones de carrera (ej., al actualizar un contador global).
* **`Sem√°foro`:** Se emplea para **controlar las conexiones simult√°neas** a la fuente externa, evitando la sobrecarga o el bloqueo por parte del servidor de destino.

---

### 5. M√≥dulo de Metadatos

Asegura la trazabilidad y la integridad de los datos descargados.

* **Almacenamiento:** Guarda la informaci√≥n esencial de cada imagen: **nombre, tama√±o, URL y el hash SHA256**.
* **Beneficios:**
    * Asegura la **reproducibilidad** del proceso.
    * Permite la **detecci√≥n futura de duplicados** de manera infalible.

---

### 6. Depuradores Posteriores

Scripts complementarios ejecutados tras la finalizaci√≥n de las descargas.

* **Funci√≥n 1:** **Eliminaci√≥n de im√°genes corruptas** o incompletas.
* **Funci√≥n 2:** Realiza la **deduplicaci√≥n** final por hash (`SHA256`) utilizando scripts de apoyo.

## 5. Problemas Reales Durante el Desarrollo y Soluciones

Esta secci√≥n detalla los principales obst√°culos encontrados durante la implementaci√≥n y las soluciones t√©cnicas aplicadas, lo que demuestra el cumplimiento de objetivos y el aprendizaje t√©cnico adquirido.

---

## 5.1. Descarga de im√°genes irrelevantes

El principal desaf√≠o en la fase de extracci√≥n fue la **baja precisi√≥n** de los resultados de b√∫squeda de la fuente (`Bing Images`).

* **Problema Real:** Al buscar un t√©rmino t√©cnico y espec√≠fico como **"multimeter"** (mult√≠metro), la herramienta de b√∫squeda tend√≠a a devolver im√°genes contextualmente irrelevantes, tales como sillas, escritorios o fotograf√≠as de personas utilizando el mult√≠metro, en lugar del dispositivo en s√≠.
* **Soluciones Aplicadas:**
    1.  **Ajuste del Keyword:** Se implement√≥ una estrategia de **ajuste fino de los t√©rminos de b√∫squeda** para intentar acotar los resultados.
    2.  **Curado en Limpieza Posterior:** Se asumi√≥ una fase de **curado manual o semiautom√°tico** como parte del proceso de limpieza posterior para descartar im√°genes no deseadas.
    3.  **Balance de Dataset:** Posteriormente, para diversificar y mejorar la calidad del conjunto de datos, se a√±adi√≥ el t√©rmino **"transistor"** a la lista de keywords, buscando **balancear** la tipolog√≠a de las im√°genes.

---

### 5.2. Tiempo excesivo de Extracci√≥n (>10 horas)

La optimizaci√≥n del tiempo de ejecuci√≥n fue cr√≠tica, ya que el proceso inicial consum√≠a una cantidad de tiempo inaceptable para la escala de datos requerida.

* **Problema Real:** La extracci√≥n de aproximadamente **2000 im√°genes limpias** requiri√≥ un tiempo de ejecuci√≥n excesivamente largo, lo que afect√≥ la productividad y la iteraci√≥n del desarrollo:
    * **5 horas** con Firefox (El proceso fall√≥ por errores de perfil del navegador).
    * **M√°s de 10 horas en total** para completar las extracciones de solo dos clases con la implementaci√≥n inicial de **Selenium**.
* **Intentos de Soluci√≥n Fallidos:**
    * Se intent√≥ alternar el *driver* de Selenium entre **Chromium** y **Firefox** para buscar una ganancia de rendimiento, sin √©xito significativo.
    * Se evaluaron m√©todos externos como la librer√≠a **`bing_image_downloader`**, pero se descartaron por falta de flexibilidad o control.
* **Soluci√≥n Final Adoptada (Combinaci√≥n de Enfoques):**
    1.  **Scraping Multithreading:** Se implement√≥ y optimiz√≥ un sistema de **scraping concurrente** utilizando **`multithreading`** para manejar la mayor√≠a de las descargas en paralelo.
    2.  **Herramienta Alternativa Espec√≠fica:** Se utiliz√≥ una **herramienta alternativa espec√≠fica** para la extracci√≥n del subconjunto de im√°genes de **"transistores"**, aprovechando su eficiencia para esa tarea concreta.
    3.  **Limpieza Posterior Autom√°tica:** La dependencia en una **limpieza posterior autom√°tica** se increment√≥ para manejar la escala de datos extra√≠dos r√°pidamente, compensando la velocidad de extracci√≥n con un proceso de filtrado robusto.

### 5.3. Eliminaci√≥n masiva ‚Äî P√©rdida del 40‚Äì60% de im√°genes

Despu√©s del dedupe por hash:
  ```bash
  Eliminados: 1189
  ```
- Causas:

  - Im√°genes duplicadas en miniaturas/HD.

  - Servidores devolv√≠an la misma imagen con URLs diferentes.

  - Historias de cache del buscador.

- Resultado final:

  - Todas las carpetas quedaron con m√°s de 100 im√°genes v√°lidas.
  - Aunque no se alcanz√≥ exactamente 200 por clase, el dataset es consistente y limpio.

  ## 7. Conclusiones del Punto 1: Logros y Aprendizajes

La ejecuci√≥n exitosa de este proyecto de construcci√≥n de dataset y sistema de scraping condujo a los siguientes logros y aprendizajes clave:

---

### Logros del Proyecto

* **Construcci√≥n de un Dataset Personalizado para el Laboratorio:** Se logr√≥ crear un dataset de alta calidad, curado y espec√≠fico, con una cantidad de m√°s de 100 im√°genes por clase despu√©s de la fase de limpieza y depuraci√≥n.
* **Desarrollo de un Sistema de Scraping Robusto y Realista:** Se dise√±√≥ y codific√≥ un sistema de extracci√≥n que demostr√≥ ser capaz de realizar trabajo intensivo de larga duraci√≥n, resolviendo desaf√≠os reales de estabilidad y gesti√≥n de errores.
* **Implementaci√≥n de T√©cnicas Avanzadas de Concurrencia:** Se aplicaron con √©xito principios de multithreading y sincronizaci√≥n (Lock, Semaphore) en una aplicaci√≥n real, con impactos tangibles en la reducci√≥n del tiempo de procesamiento.

---

### Aprendizajes Clave

* **L√≠mites y Fallos Comunes del Scraping:** Se obtuvo una experiencia pr√°ctica profunda en el manejo y mitigaci√≥n de problemas intr√≠nsecos al web scraping a gran escala, incluyendo:
    * **Bloqueos de IP:** Estrategias para evadir o manejar las restricciones del servidor fuente.
    * **Im√°genes Ruidosas:** Gesti√≥n de im√°genes con contenido contextual irrelevante.
    * **Contenidos No Relevantes:** Filtrado efectivo de resultados que no cumplen con los requisitos de la clase (ej., errores de keyword).
    * **Duplicados Masivos:** Implementaci√≥n de hashing (SHA256) para la detecci√≥n y eliminaci√≥n eficiente.

* **Generaci√≥n de una Arquitectura Escalable:** El dise√±o modular y desacoplado del sistema sent√≥ las bases para la escalabilidad y la integraci√≥n futura con m√≥dulos de Machine Learning para los siguientes objetivos del proyecto:
    * Clasificaci√≥n con MediaPipe.
    * Reconocimiento de elementos.
    * Implementaci√≥n del sistema final en Streamlit.

  ---

## üìÅ Estructura del proyecto: tree + explicaci√≥n completa

A continuaci√≥n se muestra la estructura final del proyecto de Web Scraping con Python, enriquecida con una explicaci√≥n exhaustiva de cada componente:

**webscrapping/**
* **venv/**
    * ... (Entorno virtual con dependencias)
* **dataset/**
    * [Carpetas de Clases]
        * breadboard/
        * capacitor_electronic_component/
        * diode_electronic_component/
        * function_generator/
        * multimeter/
        * oscilloscope/
        * resistor_electronic_component/
        * soldering_iron/
        * stepper_motor/
        * transistor_electronic_component/
* **metadata/**
    * metadata.csv (Registro formal y trazabilidad del dataset)
* **Archivos Ejecutables y Scripts**
    * scraper\_dataset.py (Scraper PRINCIPAL: Multihilo, Sem√°foros, Mutex)
    * fast\_download\_transistor.py (Script alterno/de emergencia)
    * check\_corrupt.py (Script para detectar y registrar im√°genes da√±adas)
    * dedupe\_by\_hash.py (Script para eliminaci√≥n masiva de duplicados por hash SHA-256)
    * README.md (Documentaci√≥n principal del proyecto)
  * **Dockerfile**
  * **requirements.txt**

## üß© Explicaci√≥n de las Carpetas y Archivos Principales

A continuaci√≥n se detalla la funci√≥n de cada directorio y archivo clave dentro de la estructura del proyecto.

---

### 1. `venv/` ‚Äî Entorno Virtual üß™

Este directorio es esencial para la gesti√≥n de dependencias del proyecto. 

* **Funci√≥n Principal:** Contiene todas las **dependencias de Python** de forma aislada del sistema operativo principal.
* **Prop√≥sito:**
    * **Evita conflictos de versiones** con librer√≠as o paquetes instalados globalmente en el sistema.
    * Aloja librer√≠as espec√≠ficas utilizadas en el proyecto, como **`requests`**, **`Pillow`**, **`bing_image_downloader`**, **`beautifulsoup4`**, etc.
    * **Garantiza la portabilidad:** Asegura que cualquier desarrollador que ejecute el proyecto tenga **exactamente el mismo entorno** de trabajo.
* **Estatus:** Es una carpeta indispensable para el desarrollo profesional y reproducible de proyectos en Python.

---

### 2. `dataset/` ‚Äî Carpetas con las Im√°genes Finales üíæ

Este directorio almacena la salida principal del proceso de *scraping* y limpieza: el conjunto de datos final.

* **Funci√≥n Principal:** Contiene todas las **clases (categor√≠as)** que componen el *dataset*.
* **Estructura Interna:** Cada clase se representa mediante una subcarpeta dentro de `dataset/`.
* **Nomenclatura:** Las carpetas de clase tienen un **nombre normalizado** para facilitar el procesamiento posterior por modelos de Machine Learning.

- Ejemplos:

  - breadboard/

  - multimeter/

  - transistor_electronic_component/

  Cada carpeta dentro de `dataset/` contiene las siguientes caracter√≠sticas despu√©s del proceso de curado:

* **Im√°genes V√°lidas:** Solo incluye im√°genes que han pasado el proceso de deduplicaci√≥n (sin duplicados).
* **Im√°genes NO Corruptas:** Todos los archivos han sido verificados y garantizan su integridad estructural.
* **Cantidad Final:** **M√°s de 100 im√°genes por clase** despu√©s de la limpieza.

> **Nota:** Aunque el objetivo inicial era de 200 im√°genes por clase, los desaf√≠os inherentes al *scraping* (problemas de precisi√≥n en Bing, el exceso de im√°genes basura y la enorme cantidad de duplicados) redujeron el total final. Esta limitaci√≥n cuantitativa se justifica y explica detalladamente en el **README t√©cnico** del proyecto.

---

### 3. `metadata/metadata.csv` ‚Äî Registro Formal del Dataset üìÑ

Este archivo es crucial para la **trazabilidad, auditor√≠a y reproducibilidad** del conjunto de datos. En proyectos serios de *Machine Learning* y an√°lisis de datos, el registro formal del origen y estado de cada muestra es un requisito clave.



**Campos T√≠picos del `metadata.csv`:**

| Campo | Descripci√≥n |
| :--- | :--- |
| `image_path` | La ruta relativa al archivo dentro de la carpeta `dataset/`. |
| `class` | La categor√≠a o etiqueta a la que pertenece la imagen (ej. 'multimeter', 'transistor'). |
| `resolution` | La resoluci√≥n de la imagen (ej. '640x480'). |
| `file_size` | El tama√±o del archivo en bytes. |
| `hash_sha256` | El **hash criptogr√°fico SHA256**, fundamental para la detecci√≥n de duplicados y la verificaci√≥n de integridad. |
| `is_corrupt` | Indicador booleano que registra si la imagen fue marcada como corrupta (deber√≠a ser **False** para todas las entradas finales). |
| `duplicate_of` | Si es un duplicado, registra el `image_path` del archivo original que se conserv√≥. |

## 4. `scraper_dataset.py` ‚Äî Scraper PRINCIPAL Multihilo (con Sem√°foros y Mutex)

Este script es el **archivo m√°s importante y central** de todo el proyecto, conteniendo la l√≥gica de concurrencia y la gesti√≥n robusta de errores para la descarga de im√°genes.

---

### Funcionalidades Clave y T√©cnicas de Concurrencia

El script implementa t√©cnicas avanzadas de programaci√≥n concurrente para optimizar el rendimiento y garantizar la integridad de los datos:

* **Uso de Threads (Hilos):**
    * **Prop√≥sito:** Se utilizan para ejecutar la descarga de **m√∫ltiples im√°genes en paralelo**. 
    * **Impacto:** Sin la concurrencia, el proceso de *scraping* habr√≠a tardado un estimado de **40 a 60 horas**.

* **Uso de Sem√°foros (`Semaphore`):**
    * **Funci√≥n:** Se implementa un **sem√°foro** para **limitar el n√∫mero de descargas simult√°neas** a un valor seguro (ejemplo: `semaphore = threading.Semaphore(8)`).
    * **Beneficios:**
        * Evita **bans temporales** por parte de la fuente (`Bing Images`).
        * Previene **errores por saturaci√≥n** del servidor de destino.
        * Minimiza **timeouts masivos** y el riesgo de saturar la CPU o el ancho de banda local.

* **Uso de Mutex (`Lock`):**
    * **Necesidad:** El mutex (o `Lock`) es necesario porque, aunque las im√°genes se descargan en paralelo, **varios hilos deben escribir simult√°neamente** en recursos compartidos, como:
        * El archivo de registro de metadatos (`metadata.csv`).
        * **Contadores globales** de progreso o errores.
    * **Resultado:** El uso del mutex **evita *race conditions*** (condiciones de carrera) y previene la **corrupci√≥n** del archivo CSV, garantizando la escritura at√≥mica de los datos.

---

### Gesti√≥n de Errores y Almacenamiento

El script garantiza la fiabilidad del proceso de descarga mediante control de calidad y robustez:

* **Descarga con Control de Errores Robusto:**
    * **Manejo de Timeouts:** Implementa estrategias de reintento ante fallos de conexi√≥n o tiempos de espera agotados.
    * **Retry Autom√°tico:** Intenta autom√°ticamente la descarga un n√∫mero predefinido de veces antes de marcar una tarea como fallida.
    * **Sanitizaci√≥n del Nombre del Archivo:** Procesa y limpia el nombre del archivo para asegurar la compatibilidad con diferentes sistemas operativos.
    * **Verificaci√≥n de Contenido:** Valida que el archivo descargado sea efectivamente una imagen (ej., contenido tipo `image/jpeg`, `image/png`), descartando posibles archivos HTML o corruptos.

* **Guardado y Organizaci√≥n:** Guarda cada imagen en su **carpeta de clase correspondiente** dentro del directorio `dataset/`, manteniendo la estructura organizada.

### 5. `fast_download_transistor.py` ‚Äî Script Alterno de Emergencia üöÄ

Este script fue desarrollado como una **soluci√≥n de contingencia** para mitigar los problemas de eficiencia y precisi√≥n del *scraper* principal en clases problem√°ticas.

* **Motivaci√≥n:** Se cre√≥ debido a:
    * El tiempo excesivo de ejecuci√≥n del *scraper* principal (**m√°s de 10 horas**).
    * El fallo en completar el objetivo de 200 im√°genes en algunas clases.
    * La alta tasa de **im√°genes irrelevantes** (sillas, autos, etc.) devueltas por Bing.
    * El componente **"transistor"** fue particularmente problem√°tico en la extracci√≥n.

* **Implementaci√≥n:** Utiliza la librer√≠a **`bing_image_downloader`**, pero requiri√≥ una **modificaci√≥n interna del m√≥dulo** debido a:
    * Un **bug** relacionado con la funci√≥n `Path.isdir` en el entorno de desarrollo.
    * La necesidad de **adaptar el flujo de descarga** para integrarlo con la estructura de carpetas del proyecto.

* **Uso:** Solo se emple√≥ una vez para **completar una clase puntual** (la de transistores) y balancear el *dataset*.

---

### 6. `check_corrupt.py` ‚Äî Script para Detectar Im√°genes Da√±adas üõ°Ô∏è

Este script de post-procesamiento garantiza la **integridad y usabilidad** de todos los archivos descargados.

* **Mecanismo de Verificaci√≥n:** Revisa iterativamente cada archivo dentro del directorio `dataset/`.
    * **Proceso:** Intenta abrir la imagen utilizando la librer√≠a **PIL (Pillow)**.
    * **Acci√≥n:** Si la apertura falla, la imagen es marcada como **corrupta** y el estado se **registra en `metadata.csv`**. Opcionalmente, el script puede ser configurado para eliminar el archivo f√≠sicamente.

* **Importancia Cr√≠tica:** Este script fue **crucial** porque:
    * Bing entreg√≥ una cantidad significativamente alta de **im√°genes corruptas** o incompletas.
    * Se detectaron casos de archivos que eran realmente **c√≥digo HTML disfrazado de JPG** (un error com√∫n de *scraping*).

---

### 7. `dedupe_by_hash.py` ‚Äî Eliminaci√≥n Masiva de Duplicados ‚öôÔ∏è

Este script asegura la **unicidad** del *dataset*, un paso fundamental para evitar el sesgo en el entrenamiento de modelos de *Machine Learning*.

* **Proceso Central:**
    * **C√°lculo de Hash:** Calcula el **hash SHA-256** de cada imagen. Esta es la t√©cnica m√°s robusta y **garantiza detectar duplicados** incluso si los archivos tienen nombres o metadatos distintos. 
    * **Eliminaci√≥n:** **Elimina autom√°ticamente los duplicados reales**. En la ejecuci√≥n del proyecto, el resultado fue: **Eliminados: 1189** archivos.

* **Justificaci√≥n de Duplicados:** La alta tasa de duplicados es normal debido a:
    * La repetici√≥n masiva de contenido por parte de la fuente (`Bing`).
    * La similitud entre las clases del *dataset*.
    * La tendencia del buscador a devolver **clones reescalados** de la misma imagen.

* **Registro:** **Actualiza el `metadata.csv`**, marcando cu√°l archivo fue duplicado de cu√°l, manteniendo un registro de la limpieza.

![Image](https://github.com/user-attachments/assets/87457fb1-c937-48c2-b33d-3907dcc1ac2c)
>- Carpetas
---

![Image](https://github.com/user-attachments/assets/f716ea5b-7411-4878-80f3-75370a5ab821)
>- Dataset luego del primer web scrapping (sin limpieza)
---


![Image](https://github.com/user-attachments/assets/9ed39431-7098-4396-848e-860c054e8628)
>- Verificaci√≥n imagenes corruptas
---

![Image](https://github.com/user-attachments/assets/f1d3aa2e-0535-4a78-ab7a-7c0679a83069)
>- Limpieza de imagenes 
---
![Image](https://github.com/user-attachments/assets/7a29297c-70a9-456e-8e5b-2bf1c23a2d70)
>- Limpieza semantica de imagenes ejemplo 1
---

![Image](https://github.com/user-attachments/assets/e6d7a427-5322-43e7-8d54-0ef314cc91fc)
>- Limpieza semantica de imagenes ejemplo 2
---

![Image](https://github.com/user-attachments/assets/3f3d7489-9a38-4b8d-ad4f-1af62686d606)
>- Limpieza semantica de imagenes ejemplo 3
---

![Image](https://github.com/user-attachments/assets/e5b0c03b-132c-475b-97d4-8f8d0a91936d)
>- Cantidad de imagenes despues de la limpieza
---

![Image](https://github.com/user-attachments/assets/80ca9f7a-c417-40f2-b8ef-f4cca9ddaeec)
>- Cantidad de imagenes despues de un nuevo web scrapping y limpieza
---


![Image](https://github.com/user-attachments/assets/3f6283f9-6d0e-4a83-a686-0a926118ed67)
>- Redimension de im√°genes y conteo final
---

# Punto 3 - Sistema de Detecci√≥n en Tiempo Real con Streamlit, YOLO, Seguimiento de Velocidad y Docker üê≥

En este punto  se integra un sistema completo para visi√≥n artificial en tiempo real, combinando:

- Detecci√≥n de personas
- C√°lculo de velocidad por seguimiento con Centroid Tracking
- Detecci√≥n de componentes electr√≥nicos (osciloscopio, mult√≠metro, raspberry‚Ä¶) con YOLO personalizado
- Procesamiento paralelo (multithreading) con semaforizaci√≥n natural usando colas
- Interfaz web en tiempo real desarrollada en Streamlit
- Contenedorizaci√≥n con Docker
- Entrenamiento de un clasificador CNN
- Generaci√≥n autom√°tica de clases

------------

## üèóÔ∏è 1. Arquitectura General del Proyecto

El sistema se divide en m√≥dulos independientes que cooperan:    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   Streamlit (Frontend)     ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
            Actualizaci√≥n UI
                   ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ        Procesos              ‚îÇ
    ‚îÇ  (Threads independientes)    ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ              ‚îÇ               ‚îÇ
    ‚ñº              ‚ñº               ‚ñº
    Captura     Personas         Componentes
      |        (Tracking)           (YOLO)
      |             |                |
      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ Cola Q ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Cada m√≥dulo corre en un hilo separado, sincronizado mediante queues, que funcionan como buffers que evitan bloqueos y regulan el acceso concurrente (semaforizaci√≥n impl√≠cita).

------------

## üé• 2. M√≥dulo de Captura de Video ‚Äî VideoCaptureThread

üìå Encargado de:

- Abrir la c√°mara
- Leer frames continuamente (sin bloquear la interfaz)
- Duplicar cada frame hacia dos pipelines independientes:
	- frame_q_person ‚Üí Detecci√≥n y velocidad
	- frame_q_comp ‚Üí YOLO componentes

‚úîÔ∏è Se usa time.sleep(0.01) para evitar overrun
‚úîÔ∏è El hilo es daemon, cierra autom√°ticamente
‚úîÔ∏è Los buffers Queue(maxsize=2) cumplen funci√≥n de mutex + sem√°foro

- Si la cola est√° llena, descarta entrada ‚Üí evita backpressure

------------

# Punto 3 - Sistema de Detecci√≥n en Tiempo Real con Streamlit, YOLO, Seguimiento de Velocidad y Docker üê≥

En este punto  se integra un sistema completo para visi√≥n artificial en tiempo real, combinando t√©cnicas avanzadas de visi√≥n artificial, arquitectura concurrente y despliegue en contenedores. A continuaci√≥n se explica el funcionamiento interno hasta las decisiones de dise√±o tomadas durante el desarrollo.

------------

## üìå Contenido

1. Arquitectura completa del sistema
2. M√≥dulo de captura
3. M√≥dulo de seguimiento y velocidad
4. Hilo de detecci√≥n por YOLO
5. Interfaz visual con Streamlit
6. Scripts auxiliares
7. Dockerizaci√≥n completa
8. Errores encontrados y decisiones de dise√±o
9. Explicaci√≥n profunda de hilos, sem√°foros y mutex
10. 

------------

## üèóÔ∏è 1. Arquitectura General del Sistema

El sistema fue dise√±ado bajo procesamiento paralelo, manteniendo una UI fluida incluso mientras:

- Se captura video en tiempo real
- Se procesan personas y su velocidad
- Se ejecutan modelos YOLO personalizados
- Se actualiza la interfaz en dos paneles simult√°neamente

Esto se logra mediante tres hilos principales:

    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ       Streamlit (UI)         ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
            Actualizaci√≥n de la UI
                    ‚îÇ
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ      Procesos (threads) ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ      ‚îÇ
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îê ‚îå‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ CapturaVideo ‚îÇ ‚îÇ YOLOComponent ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ                ‚îÇ
        Frame duplicado      Frame duplicado
               ‚îÇ                ‚îÇ
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ Cola personas ‚îÇ   ‚îÇ Cola comp   ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚ñº               ‚ñº
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
     ‚îÇ         PersonProcessor              ‚îÇ
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Cada m√≥dulo corre en un hilo separado, sincronizado mediante queues, que funcionan como buffers que evitan bloqueos y regulan el acceso concurrente (semaforizaci√≥n impl√≠cita).

Los Queue(maxsize=2) act√∫an como:

‚úî mini-buffers
‚úî sem√°foros impl√≠citos
‚úî reguladores de concurrencia
‚úî anti-lag para evitar cuellos de botella

------------

## üé• 2. M√≥dulo de Captura de Video ‚Äî VideoCaptureThread

üìå Encargado de:

- Abrir la c√°mara
- Leer frames continuamente (sin bloquear la interfaz)
- Duplicar cada frame hacia dos pipelines independientes:
	- frame_q_person ‚Üí Detecci√≥n y velocidad
	- frame_q_comp ‚Üí YOLO componentes

‚úîÔ∏è Se usa time.sleep(0.01) para evitar overrun
‚úîÔ∏è El hilo es daemon, cierra autom√°ticamente
‚úîÔ∏è Los buffers Queue(maxsize=2) cumplen funci√≥n de mutex + sem√°foro

- Si la cola est√° llena, descarta entrada ‚Üí evita backpressure

Este hilo es el coraz√≥n del sistema porque:

### ‚úî Evita que Streamlit se bloquee

Un error com√∫n es capturar frames directamente dentro de Streamlit, lo cual congela la UI.
Aqu√≠, capturamos en un hilo dedicado.

### ‚úî Duplicaci√≥n de frames

Cada frame le√≠do se divide hacia dos pipelines independientes:

- personas ‚Üí an√°lisis de velocidad
- componentes ‚Üí YOLO personalizado

Esto es m√°s eficiente que abrir la c√°mara dos veces.

### ‚úî ¬øC√≥mo funciona la semaforizaci√≥n?

La cola funciona como un sem√°foro:

- Si la cola est√° llena ‚Üí descarta frames viejos
- Si est√° vac√≠a ‚Üí el thread consumidor espera

Esto evita condiciones de carrera.

------------

## üèÉ‚Äç‚ôÇÔ∏èüí® 3. Seguimiento y Velocidad ‚Äî PersonProcessor

Este m√≥dulo combina:

### 1Ô∏è‚É£ Detecci√≥n de personas

Preferencia:

1. MobileNetSSD (ligero, eficiente)
2. YOLOv11n (si no est√° MobileNet)

### 2Ô∏è‚É£ CentroidTracker personalizado

El sistema identifica cada persona con un ID constante.

Incluye:

- Registro
- Desaparici√≥n gradual
- Reasignaci√≥n inteligente por distancias

### 3Ô∏è‚É£ C√°lculo real de velocidad

Sistema basado en:

    velocidad = distancia_en_metros / tiempo

Donde:

    metros = pixeles * pixels_to_m

Este valor se calibra desde la UI.

### 4Ô∏è‚É£ Suavizado con historial

Historial de centroides ‚Üí evita ruido ‚Üí velocidad estable.

------------

## üõ†Ô∏è 4. Detecci√≥n de Componentes ‚Äî ComponentsProcessor

Este m√≥dulo carga el modelo YOLO personalizado:

    /home/arley/segmentacion/model/best.pt

Clases detectadas:

- Mult√≠metro
- Osciloscopio
- Raspberry Pi

‚úî Verbose desactivado ‚Üí m√°s rendimiento
‚úî Colores distintos por clase
‚úî Tambi√©n usa colas para semaforizaci√≥n
‚úî Procesamiento completamente paralelo a personas

------------

## üñ•Ô∏è 5. Interfaz Web con Streamlit ‚Äî streamlit_app.py

La UI incluye:

‚úîÔ∏è Dos columnas principales

| Izquierda            | Derecha          |
| -------------------- | ---------------- |
| Personas + velocidad | YOLO componentes |

‚úîÔ∏è Botones de control

- Iniciar
- Detener

‚úîÔ∏è Sidebar editable

- √çndice de c√°mara
- Factor de calibraci√≥n pixels_to_m

‚úîÔ∏è Actualizaci√≥n fluida sin parpadeo

Gracias a:

- last_person_img
- last_comp_img

Se actualiza solo si llega un nuevo frame, evitando ‚Äúflash‚Äù.

![Prueba del Programa](https://github.com/yojan-maker/Proyecto/blob/main/Proyecto/Mediapipe_Yolo/yolo%201.jpeg?raw=true)

![Prueba con Multimetro](https://github.com/yojan-maker/Proyecto/blob/main/Proyecto/Mediapipe_Yolo/yolo%202.jpeg?raw=true)

![Prueba con RaspBerryPi](https://github.com/yojan-maker/Proyecto/blob/main/Proyecto/Mediapipe_Yolo/yolo%203.jpeg?raw=true)

![Prueba con Osciloscopio](https://github.com/yojan-maker/Proyecto/blob/main/Proyecto/Mediapipe_Yolo/yolo%204.jpeg?raw=true)

------------

## üß© 6. Scripts Auxiliares

### 6.1. Generador de clases ‚Äî generate_class_names.py

Genera autom√°ticamente class_names.json seg√∫n subcarpetas del dataset.

Ideal para:

- Clasificadores
- Keras
- Exportaci√≥n din√°mica

### 6.2. train_classifier.py

Entrena un modelo CNN basado en MobileNetV2:

- Data augmentation
- EarlyStopping
- Checkpoints
- LR scheduler
- Exporta model.h5

### 6.3. utils_tracker.py

Versi√≥n modular del CentroidTracker.

Incluye:

- Registro
- Deregistro
- Distancias
- Historial
- C√°lculo de velocidad

------------

## üê≥ 7. Dockerizaci√≥n del Proyecto

El proyecto se ejecuta en cualquier servidor gracias al Dockerfile:

El archivo principal es:

‚úîÔ∏è Dockerfile_mediapipe

Incluye:

üß© Base ligera:
    FROM python:3.10-slim

üèóÔ∏è Instalaci√≥n de dependencias del sistema:

Se instalan:

- libgl1-mesa-glx ‚Üí OpenCV
- libglib2.0-0
- libgomp1 ‚Üí necesaria para YOLO

üß™ Instalaci√≥n de dependencias Python:

    pip install --no-cache-dir -r requirements.txt

‚ñ∂Ô∏è Comando de ejecuci√≥n:

    streamlit run streamlitapp.py --server.port=8501 --server.address=0.0.0.0

### Proceso de Dockerizacion

1. docker build
2. docker tag
3. docker push
4. subir imagen al registry

![Dockerizacion](https://github.com/yojan-maker/Proyecto/blob/main/Proyecto/Mediapipe_Yolo/dock1.jpeg?raw=true)

![Dockerizacion](https://github.com/yojan-maker/Proyecto/blob/main/Proyecto/Mediapipe_Yolo/dock3.jpeg?raw=true)

![Dockerizacion](https://github.com/yojan-maker/Proyecto/blob/main/Proyecto/Mediapipe_Yolo/dock4.jpeg?raw=true)

Dockerhub
https://hub.docker.com/r/yojancg/streamlit-yolo/tags

------------

##  8. Problemas Encontrados y Decisiones Tomadas
# ‚öôÔ∏è Decisiones T√©cnicas y Arquitectura del Sistema

---

## 2. üü• Decisiones T√©cnicas Tomadas (Justificaci√≥n)

Despu√©s de evaluar varios enfoques, el sistema final adopt√≥ la siguiente pila tecnol√≥gica para asegurar un rendimiento √≥ptimo en **tiempo real**.

### 2.1. MobileNetSSD para detectar personas
**Razones de Adopci√≥n:**

* **Muy ligero:** Implementado en **Caffe**, ideal para entornos con recursos limitados.
* **Estable en CPU:** Garantiza un rendimiento consistente sin depender de una GPU dedicada.
* **R√°pido:** Alcanza una tasa de **20-40 FPS** (Frames Per Second).
* **Bounding Boxes Consistentes:** Genera cuadros delimitadores amplios pero estables, ideales para el c√°lculo de **tracking** y **centroides**.
* **Ideal para Tracking + Centroides:** Su ligereza y consistencia son perfectas para el subsistema de seguimiento.
* **Evita Carga Pesada:** Previene el alto consumo de recursos que generar√≠a un modelo m√°s grande como YOLO.

**MediaPipe fue descartado** debido a problemas de:
* ‚ùå Rendimiento inconsistente.
* ‚ùå Compatibilidad en el entorno de producci√≥n.
* ‚ùå Congelamiento inesperado dentro del _framework_ **Streamlit**.

### 2.2. YOLOv11 personalizado SOLO para objetos electr√≥nicos
Se decidi√≥ **no usar un √∫nico YOLO para todo** (personas + componentes) debido a que YOLO, aunque potente, presenta los siguientes inconvenientes en este contexto de tiempo real:

* ‚ùå **Consume m√°s CPU** por _frame_.
* ‚ùå Tiende a detectar **personas como otros objetos**, generando falsos positivos.
* ‚ùå Disminuye el **framerate general** del sistema.
* ‚ùå Rompe la l√≥gica de c√°lculo del **tracking**.
* ‚ùå Genera **latencias inconsistentes**.

> **Conclusi√≥n:** Dividir los dos procesos de detecci√≥n (Personas y Componentes) es **obligatorio** en sistemas que requieren una respuesta en **tiempo real**.

### 2.3. Arquitectura Multihilo (3 threads)

Se dise√±√≥ un sistema basado en la **Arquitectura Productor-Consumidor** con tres hilos (**threads**) independientes:

| Hilo | Funci√≥n Principal | Modelo Utilizado |
| :--- | :--- | :--- |
| **`VideoCaptureThread`** | üé• Lee la c√°mara continuamente y distribuye frames. | N/A |
| **`PersonProcessor`** | üßç Detecta personas, calcula centroides y estima velocidad. | MobileNetSSD |
| **`ComponentsProcessor`** | üì± Detecta componentes electr√≥nicos y devuelve _bounding boxes_. | YOLOv11 Personalizado |

* **Ventaja:** Ninguno de los procesos (detecci√≥n de personas, detecci√≥n de componentes) bloquea al otro, manteniendo el flujo de datos constante.

### 2.4. Colas (`Queue`) para sincronizar hilos

Se usaron estructuras de **colas (`Queue`)** para gestionar la comunicaci√≥n entre hilos:

* **Comunicaci√≥n Segura:** Permite el intercambio de datos entre hilos sin riesgo.
* **Evita _Race Conditions_:** Garantiza que los hilos no accedan o modifiquen el mismo recurso simult√°neamente.
* **Buffers Peque√±os:** Las colas se configuraron para mantener solo los **frames m√°s recientes (m√°ximo 2)** para:
    * Evitar desbordamientos de memoria.
    * Mantener la baja **latencia** y evitar retrasos acumulados (lag).

### 2.5. Persistencia de im√°genes para evitar parpadeos

Para mitigar el **flickering** (parpadeo) o la aparici√≥n de pantallas negras en la interfaz de usuario:

* **Mecanismo:** Si el detector (YOLO o MobileNetSSD) se demora en procesar un nuevo _frame_, se muestra el **√∫ltimo _frame_ v√°lido** que se proces√≥ correctamente.
* **Implementaci√≥n:** Se usa una variable de persistencia como `last_person_img` para almacenar el √∫ltimo resultado consistente.

---

## 3. üü• Arquitectura Completa del Sistema (Detallada)

Esta secci√≥n explica la arquitectura interna del sistema a nivel de ingenier√≠a de software. 

### 3.1. Captura de Video (`VideoCaptureThread`)

Este hilo es el **√∫nico productor de _frames_** en el sistema y se ejecuta de la siguiente manera:

1.  **Independiente:** Se ejecuta de forma as√≠ncrona.
2.  **Apertura √önica:** Abre la c√°mara (o fuente de video) solo una vez.
3.  **Lectura M√°xima:** Lee los _frames_ a la m√°xima velocidad que la c√°mara permite.
4.  **Clonaci√≥n y Distribuci√≥n:** Clona el _frame_ le√≠do y lo env√≠a a **dos colas diferentes**:
    * `frame_q_person` ‚Üí Usada por el `PersonProcessor` (para tracking humano).
    * `frame_q_comp` ‚Üí Usada por el `ComponentsProcessor` (para detecci√≥n de componentes con YOLO).

####  Problema del Acceso M√∫ltiple
Si ambos procesadores intentaran leer la c√°mara directamente (sin un hilo productor):
* ‚ùå Se genera un **conflicto** de acceso al recurso.
* ‚ùå Ambos hilos **pelean por la c√°mara**.
* ‚ùå La c√°mara puede entregar **_null frames_** o im√°genes corruptas.
* ‚ùå **Streamlit "parpadea"** o se congela.

####  Soluci√≥n
* Un **√∫nico hilo productor** de _frames_ (`VideoCaptureThread`) que garantiza el acceso serializado y consistente a la fuente de video.


------------

### 3.2. PersonProcessor ‚Äî Detecci√≥n + Tracking + Velocidad

Este hilo se encarga del seguimiento humano y del c√°lculo de movimiento.

**Tareas Principales:**

* Leer _frame_ de su cola (`frame_q_person`).
* Detectar persona con **MobileNetSSD** (o un YOLOv11n ligero).
* Generar _bounding boxes_.
* Actualizar **centroides** con el `CentroidTracker`.
* Estimar la **velocidad** de la persona.
* Enviar el resultado final a Streamlit para renderizado.

**Por qu√© se usa Tracking basado en Centroides:**

El algoritmo basado en centroides fue elegido por sus ventajas en sistemas en tiempo real:

* Es **extremadamente eficiente** en el uso de CPU.
* Permite realizar **c√°lculos de velocidad** precisos.
* Asocia un **ID √∫nico** a cada persona rastreada.
* Mantiene un **historial de movimiento** para evitar saltos (_jumps_).
* Es **resistente a oclusi√≥n temporal** (si la persona se oculta brevemente).

### 3.3. ComponentsProcessor ‚Äî Detecci√≥n con YOLO

Este hilo est√° dedicado exclusivamente a la identificaci√≥n de objetos electr√≥nicos.

**Tareas Principales:**

* Leer _frame_ de su cola (`frame_q_comp`).
* Ejecutar el modelo **YOLOv11 personalizado**.
* Filtrar las clases detectadas (solo componentes electr√≥nicos).
* Dibujar los _bounding boxes_ consistentes.
* Enviar el resultado a Streamlit para renderizado.

**Por qu√© YOLO se usa en Hilo Separado:**

Ejecutar YOLO en el mismo hilo del `PersonProcessor` (el encargado del _tracking_) tiene consecuencias cr√≠ticas para el rendimiento:

* ‚ùå La **velocidad general cae** dr√°sticamente.
* ‚ùå Los **centroides no se actualizan** a tiempo, rompiendo el seguimiento.
* ‚ùå La velocidad estimada de la persona puede caer a **0.1 m/s** (lectura err√≥nea).
* ‚ùå La aplicaci√≥n **Streamlit se cuelga** por falta de _frames_.

> **Conclusi√≥n:** La separaci√≥n garantiza que el **tracking humano** (prioridad alta) no se vea afectado por la **detecci√≥n de componentes** (prioridad media).

### 3.4. Sistema de Sincronizaci√≥n (Mutex Impl√≠citos)

El dise√±o de la arquitectura elimina la necesidad de usar **mutex** (mecanismos de exclusi√≥n mutua) expl√≠citos en Python.

**Raz√≥n de la Ausencia de Mutex Expl√≠citos:**

* La estructura `Queue` (Cola) de Python act√∫a como un **buffer sincronizado**.
* Cada operaci√≥n `put()` (escribir) y `get()` (leer) es **at√≥mica** (se completa sin interrupci√≥n).
* Los hilos **no comparten memoria directamente**; se comunican solo a trav√©s de la cola.

**Ventajas de este Dise√±o:**

* ‚úî **Evita _race conditions_** (condiciones de carrera) entre los hilos.
* ‚úî Previene la **corrupci√≥n de _frames_**.
* ‚úî Garantiza la **consistencia** en los _bounding boxes_ y centroides.

### 3.5. Streamlit ‚Äî Renderizado Paralelo

Aunque la librer√≠a **Streamlit no es inherentemente multihilo**, se utiliza para visualizar las salidas de forma as√≠ncrona.

**Mecanismo de Renderizado:**

* Consume la salida procesada de las colas de resultados.
* Actualiza la interfaz del usuario con una frecuencia constante (aproximadamente **30-60 ms**).
* Utiliza **caching simple** (memoria de los √∫ltimos _frames_ v√°lidos) para mayor estabilidad.
* Crea **dos columnas independientes** en la interfaz.

**Objetivo:**

* üìå **Dos pantallas independientes:** Una dedicada a la **velocidad** y el _tracking_ (salida del `PersonProcessor`) y otra para la **detecci√≥n de componentes** (salida del `ComponentsProcessor`), sin mezclar las im√°genes ni los c√°lculos en el frontend.

---

## 4. üü• Paso a Paso Completo: Desde el Frame Hasta el Usuario

A continuaci√≥n se detalla el _pipeline_ completo de procesamiento de datos, desde la captura del _frame_ hasta su visualizaci√≥n en la interfaz de usuario. 

### PASO 1 ‚Äî La C√°mara Entrega un Frame (Productor)

El hilo **`VideoCaptureThread`** es el √∫nico responsable de la captura y distribuci√≥n de la imagen.

* Obtiene el _frame_ desde la fuente de video (c√°mara).
* **Clona** el _frame_ para evitar conflictos de acceso.
* Lo coloca en la cola de personas: **`frame_q_person`**.
* Lo coloca en la cola de componentes: **`frame_q_comp`**.

> **Frecuencia:** Este proceso ocurre aproximadamente cada **10 ms**, manteniendo la base del sistema lo m√°s actualizada posible.

### PASO 2 ‚Äî Detecci√≥n de Personas (PersonProcessor)

El hilo `PersonProcessor` trabaja con la imagen recibida de su cola:

* **Detecci√≥n:** El modelo **MobileNetSSD** detecta la clase `"person"`.
* **Bounding Box:** Genera el rect√°ngulo delimitador.
* **Centroide:** El rect√°ngulo se convierte en un punto central.
* **Tracking:** El **`CentroidTracker`** asigna un **ID √∫nico** y mantiene un historial de movimiento.
* **C√°lculo:** Se calculan las distancias recorridas y se determina la **velocidad real en m/s**.
* **Salida:** El _frame_ con los elementos procesados se pasa a Streamlit para su renderizado.

### PASO 3 ‚Äî Detecci√≥n de Componentes (ComponentsProcessor)

El hilo `ComponentsProcessor` se enfoca en la identificaci√≥n de equipo electr√≥nico:

* **Detecci√≥n:** El modelo **YOLOv11 personalizado** detecta clases espec√≠ficas (ej. mult√≠metro, osciloscopio, raspberry).
* **Filtrado:** Se descartan las clases detectadas que no son relevantes para el objetivo.
* **Bounding Boxes:** Se calculan los cuadros delimitadores para los objetos filtrados.
* **Rotulaci√≥n:** Se **colorea y rotula** el cuadro seg√∫n el tipo de componente.
* **Salida:** El _frame_ con las detecciones se env√≠a a Streamlit.

### PASO 4 ‚Äî Streamlit Actualiza UI (Consumidor Final)

La aplicaci√≥n **Streamlit** realiza la visualizaci√≥n de los dos _pipelines_ de forma **paralela**:

| Columna Izquierda (PersonProcessor) | Columna Derecha (ComponentsProcessor) |
| :--- | :--- |
| Imagen procesada con **personas y centroides**. | **Detecciones YOLO** de componentes electr√≥nicos. |
| **Velocidad** mostrada en tiempo real junto a cada persona. | Objetos **rotulados y coloreados** seg√∫n su tipo. |

> üîí **Mecanismo de Persistencia:** Si alguno de los hilos de procesamiento (`PersonProcessor` o `ComponentsProcessor`) se retrasa en la entrega de un _frame_, la interfaz usa el √∫ltimo _frame_ v√°lido almacenado en **`last_person_img`** o **`last_comp_img`**. **Esto elimina el parpadeo (flickering)** y garantiza la estabilidad visual.


---


## Conclusi√≥n General del Proyecto

El desarrollo completo de este proyecto integr√≥ de forma coherente y funcional diversas √°reas de la ingenier√≠a electr√≥nica, visi√≥n por computador, manejo de datos, programaci√≥n concurrente y despliegue de aplicaciones web. A trav√©s de las cuatro fases propuestas, se construy√≥ una soluci√≥n robusta, eficiente y totalmente operativa que cumple con los requerimientos planteados por la Universidad Santo Tom√°s.

En primer lugar, se logr√≥ implementar un sistema de web scraping avanzado, capaz de adquirir de forma automatizada un volumen considerable de im√°genes de elementos electr√≥nicos. Este proceso incluy√≥ el uso intencional de hilos, sem√°foros, exclusi√≥n mutua y colas de tareas, garantizando la integridad del dataset, reduciendo tiempos de ejecuci√≥n y evitando condiciones de carrera y bloqueos por parte de los servidores externos. El resultado fue una base de datos s√≥lida y estructurada, acompa√±ada de metadatos completos que documentan su procedencia y estado.

En segundo lugar, se construy√≥ un pipeline ETL profesional, responsable de la extracci√≥n, depuraci√≥n, validaci√≥n, transformaci√≥n y organizaci√≥n de las im√°genes. Este m√≥dulo permiti√≥ consolidar un dataset final consistente, depurado de duplicados, im√°genes corruptas o irrelevantes, y estandarizado para su uso en algoritmos de clasificaci√≥n. El proceso fue dise√±ado con una arquitectura escalable y multihilo, capaz de manejar miles de archivos con eficiencia.

En la tercera fase, se integraron dos sistemas de visi√≥n por computador en tiempo real:

detecci√≥n y seguimiento de personas con c√°lculo de velocidad mediante t√©cnicas basadas en centroides,

detecci√≥n de componentes electr√≥nicos utilizando un modelo YOLO personalizado.

Ambos sistemas fueron unificados dentro de una arquitectura concurrente que permite procesar video en vivo de forma fluida y confiable, respetando los principios de sincronizaci√≥n, paralelismo y estabilidad.

Finalmente, la totalidad de la soluci√≥n fue empaquetada y desplegada como una aplicaci√≥n web interactiva mediante Streamlit, permitiendo visualizar simult√°neamente la detecci√≥n de personas y componentes, as√≠ como las m√©tricas de velocidad. El proceso incluy√≥ la integraci√≥n en un contenedor Docker completamente funcional y su publicaci√≥n en DockerHub, otorg√°ndole portabilidad, reproducibilidad y facilidad de ejecuci√≥n en cualquier entorno.

Este proyecto representa un ejercicio completo de ingenier√≠a aplicada, combinando conceptos avanzados de concurrencia, procesamiento de im√°genes, administraci√≥n de datos, aprendizaje autom√°tico y despliegue en la nube. El resultado final es una plataforma integral, modular, bien documentada y alineada con las necesidades tecnol√≥gicas contempor√°neas de la universidad.


